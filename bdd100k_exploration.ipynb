{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "627348a7",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0994c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['savefig.dpi'] = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2d591b",
   "metadata": {
    "id": "ad2d591b"
   },
   "source": [
    "## 2. Configuration\n",
    "\n",
    "**Note**: \n",
    "- Dataset must be prepared first using `process_bdd100k_to_yolo_dataset.py` script\n",
    "- Integrity checks (image-label matching) are handled during dataset preparation\n",
    "- This notebook focuses on **visualization** using pre-computed statistics from metadata files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d33349a",
   "metadata": {
    "id": "4d33349a",
    "outputId": "91e004d3-9473-4f90-c7e7-89c89b86dcc1"
   },
   "outputs": [],
   "source": [
    "# Base directory\n",
    "BASE_DIR = Path(os.getcwd())\n",
    "\n",
    "# Primary dataset for statistics (analyze the full dataset)\n",
    "FULL_DATASET_ROOT = BASE_DIR / 'bdd100k_yolo'\n",
    "FULL_DATA_YAML = FULL_DATASET_ROOT / 'data.yaml'\n",
    "\n",
    "# Secondary dataset for visualization (use limited with representative samples)\n",
    "LIMITED_DATASET_ROOT = BASE_DIR / 'bdd100k_yolo_limited'\n",
    "LIMITED_DATA_YAML = LIMITED_DATASET_ROOT / 'data.yaml'\n",
    "\n",
    "# Check which datasets exist\n",
    "full_exists = FULL_DATA_YAML.exists()\n",
    "limited_exists = LIMITED_DATA_YAML.exists()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DATASET AVAILABILITY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Full dataset ({FULL_DATASET_ROOT.name}): {'\u2713 Found' if full_exists else '\u2717 Not found'}\")\n",
    "print(f\"Limited dataset ({LIMITED_DATASET_ROOT.name}): {'\u2713 Found' if limited_exists else '\u2717 Not found'}\")\n",
    "\n",
    "if not full_exists and not limited_exists:\n",
    "    raise FileNotFoundError(\n",
    "        \"No datasets found!\\n\\n\"\n",
    "        \"Please run the dataset preparation script first:\\n\"\n",
    "        \"  python3 process_bdd100k_to_yolo_dataset.py\\n\"\n",
    "    )\n",
    "\n",
    "# Set analysis dataset (prefer full for statistics)\n",
    "ANALYSIS_DATASET_ROOT = FULL_DATASET_ROOT if full_exists else LIMITED_DATASET_ROOT\n",
    "ANALYSIS_DATA_YAML = FULL_DATA_YAML if full_exists else LIMITED_DATA_YAML\n",
    "\n",
    "# Set visualization dataset (prefer limited for comprehensive visual coverage)\n",
    "VIZ_DATASET_ROOT = LIMITED_DATASET_ROOT if limited_exists else FULL_DATASET_ROOT\n",
    "VIZ_DATA_YAML = LIMITED_DATA_YAML if limited_exists else FULL_DATA_YAML\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ANALYSIS CONFIGURATION\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Statistics from: {ANALYSIS_DATASET_ROOT.name}\")\n",
    "print(f\"Visualizations from: {VIZ_DATASET_ROOT.name}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\n\u2713 Configuration loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e969b71",
   "metadata": {},
   "source": [
    "### Strategy\n",
    "\n",
    "**This notebook uses TWO datasets:**\n",
    "1. **FULL DATASET** (`bdd100k_yolo/`) - For comprehensive statistics and analysis\n",
    "2. **LIMITED DATASET** (`bdd100k_yolo_limited/`) - For visualizations with representative samples\n",
    "\n",
    "The limited dataset includes diverse representative samples covering:\n",
    "- All attribute combinations (weather \u00d7 scene \u00d7 time)\n",
    "- All object classes with adequate coverage\n",
    "- All individual attribute values\n",
    "- Class \u00d7 attribute combinations\n",
    "\n",
    "This ensures visualizations show all important scenarios while keeping the notebook responsive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521c0a9f",
   "metadata": {},
   "source": [
    "## 3. Load Metadata and Statistics\n",
    "\n",
    "### 3.1 Load Metadata Files\n",
    "\n",
    "Metadata files contain pre-computed statistics and representative sample information generated during dataset extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2324a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load metadata files for FULL dataset\n",
    "print(\"=\" * 90)\n",
    "print(\"LOADING FULL DATASET METADATA\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "full_metadata_dir = FULL_DATASET_ROOT / 'representative_json'\n",
    "full_metadata_by_split = {}\n",
    "full_performance_by_split = {}\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    metadata_file = full_metadata_dir / f'{split}_metadata.json'\n",
    "    \n",
    "    if metadata_file.exists():\n",
    "        with open(metadata_file, 'r') as f:\n",
    "            full_metadata_by_split[split] = json.load(f)\n",
    "        print(f\"\u2713 Loaded {split} metadata: {metadata_file.name}\")\n",
    "    else:\n",
    "        print(f\"\u26a0 Missing {split} metadata: {metadata_file.name}\")\n",
    "        full_metadata_by_split[split] = None\n",
    "    \n",
    "    # Load performance analysis data (per-image details with attributes)\n",
    "    performance_file = full_metadata_dir / f'{split}_performance_analysis.json'\n",
    "    if performance_file.exists():\n",
    "        with open(performance_file, 'r') as f:\n",
    "            full_performance_by_split[split] = json.load(f)\n",
    "        print(f\"\u2713 Loaded {split} performance data: {performance_file.name}\")\n",
    "    else:\n",
    "        print(f\"\u26a0 Missing {split} performance data\")\n",
    "        full_performance_by_split[split] = None\n",
    "\n",
    "if not any(full_metadata_by_split.values()):\n",
    "    raise FileNotFoundError(\n",
    "        \"No full dataset metadata found!\\n\"\n",
    "        \"Please run: python3 process_bdd100k_to_yolo_dataset.py\"\n",
    "    )\n",
    "\n",
    "# Load metadata files for LIMITED dataset\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"LOADING LIMITED DATASET METADATA\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "limited_metadata_dir = LIMITED_DATASET_ROOT / 'representative_json'\n",
    "limited_metadata_by_split = {}\n",
    "limited_performance_by_split = {}\n",
    "\n",
    "if limited_metadata_dir.exists():\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        metadata_file = limited_metadata_dir / f'{split}_metadata.json'\n",
    "        \n",
    "        if metadata_file.exists():\n",
    "            with open(metadata_file, 'r') as f:\n",
    "                limited_metadata_by_split[split] = json.load(f)\n",
    "            print(f\"\u2713 Loaded {split} metadata: {metadata_file.name}\")\n",
    "        else:\n",
    "            print(f\"\u26a0 Missing {split} metadata: {metadata_file.name}\")\n",
    "            limited_metadata_by_split[split] = None\n",
    "        \n",
    "        # Load performance analysis data\n",
    "        performance_file = limited_metadata_dir / f'{split}_performance_analysis.json'\n",
    "        if performance_file.exists():\n",
    "            with open(performance_file, 'r') as f:\n",
    "                limited_performance_by_split[split] = json.load(f)\n",
    "            print(f\"\u2713 Loaded {split} performance data: {performance_file.name}\")\n",
    "        else:\n",
    "            print(f\"\u26a0 Missing {split} performance data\")\n",
    "            limited_performance_by_split[split] = None\n",
    "else:\n",
    "    print(\"\u26a0 Limited dataset not found\")\n",
    "    limited_metadata_by_split = {'train': None, 'val': None, 'test': None}\n",
    "    limited_performance_by_split = {'train': None, 'val': None, 'test': None}\n",
    "\n",
    "# Load class names from data.yaml\n",
    "with open(FULL_DATA_YAML, 'r') as f:\n",
    "    dataset_config = yaml.safe_load(f)\n",
    "    class_names = dataset_config['names']\n",
    "\n",
    "print(f\"\\n\u2713 Class names loaded: {class_names}\")\n",
    "print(f\"\u2713 Performance data available for per-image attribute analysis\")\n",
    "print(\"=\" * 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c9530a",
   "metadata": {},
   "source": [
    "### 3.2 Display Metadata Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8b2c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display metadata summary for BOTH datasets - using ALL 6 metadata JSON files\n",
    "print(\"=\" * 90)\n",
    "print(\"FULL DATASET METADATA (3 splits: train/val/test)\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "# Aggregate statistics from full dataset metadata (3 files)\n",
    "# NEW STRUCTURE: representative samples are nested under statistics.representative_samples\n",
    "full_stats = {\n",
    "    'total_images': 0,\n",
    "    'total_objects': 0,\n",
    "    'representative_samples': 0,\n",
    "    'representative_objects': 0,\n",
    "    'by_split': {},\n",
    "    'total_objects_by_class': {},\n",
    "    'representative_objects_by_class': {}\n",
    "}\n",
    "\n",
    "# Initialize class totals\n",
    "for cls in class_names:\n",
    "    full_stats['total_objects_by_class'][cls] = 0\n",
    "    full_stats['representative_objects_by_class'][cls] = 0\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    if not full_metadata_by_split[split]:\n",
    "        continue\n",
    "    \n",
    "    meta = full_metadata_by_split[split]\n",
    "    stats = meta['statistics']\n",
    "    config = meta['configuration']\n",
    "    \n",
    "    # Extract from NEW metadata structure\n",
    "    total_images = stats['total_files_analyzed']  # ALL images in split\n",
    "    total_objects = sum(stats['by_class'].values())  # ALL objects in split\n",
    "    \n",
    "    # Representative samples data (nested)\n",
    "    repr_samples = stats['representative_samples']['total_selected']\n",
    "    repr_objects = sum(stats['representative_samples']['by_class'].values())\n",
    "    \n",
    "    full_stats['by_split'][split] = {\n",
    "        'images': total_images,\n",
    "        'objects': total_objects,\n",
    "        'representative_samples': repr_samples,\n",
    "        'representative_objects': repr_objects,\n",
    "        'objects_by_class': stats['by_class'],  # ALL objects\n",
    "        'representative_objects_by_class': stats['representative_samples']['by_class']  # Representative objects\n",
    "    }\n",
    "    full_stats['total_images'] += total_images\n",
    "    full_stats['total_objects'] += total_objects\n",
    "    full_stats['representative_samples'] += repr_samples\n",
    "    full_stats['representative_objects'] += repr_objects\n",
    "    \n",
    "    # Aggregate object counts (ALL objects)\n",
    "    for cls, count in stats['by_class'].items():\n",
    "        full_stats['total_objects_by_class'][cls] += count\n",
    "    \n",
    "    # Aggregate representative object counts\n",
    "    for cls, count in stats['representative_samples']['by_class'].items():\n",
    "        full_stats['representative_objects_by_class'][cls] += count\n",
    "    \n",
    "    print(f\"\\n{split.upper()} SPLIT\")\n",
    "    print(\"-\" * 90)\n",
    "    print(f\"  Generated: {meta.get('generation_date', 'N/A')}\")\n",
    "    print(f\"  Total images in full dataset: {total_images:,}\")\n",
    "    print(f\"  Total objects in full dataset: {total_objects:,}\")\n",
    "    print(f\"\\n  Representative sample selection (for limited dataset):\")\n",
    "    print(f\"    Samples selected: {repr_samples:,} ({(repr_samples/total_images*100):.2f}% of this split)\")\n",
    "    print(f\"    Objects in samples: {repr_objects:,} ({(repr_objects/total_objects*100):.2f}% of this split's objects)\")\n",
    "    \n",
    "    print(f\"\\n  Selection Configuration:\")\n",
    "    print(f\"    - Samples per attribute combo: {config['samples_per_attribute_combo']}\")\n",
    "    print(f\"    - Min samples per class: {config['min_samples_per_class']}\")\n",
    "    print(f\"    - Min samples per attribute value: {config['min_samples_per_attribute_value']}\")\n",
    "    print(f\"    - Min samples per (class\u00d7attribute): {config['min_samples_per_class_attribute_combo']}\")\n",
    "    \n",
    "    print(f\"\\n  Coverage Statistics (all images):\")\n",
    "    print(f\"    - Classes with objects: {len([k for k,v in stats['by_class'].items() if v > 0])}/{len(meta['classes'])}\")\n",
    "    print(f\"    - Weather types covered: {len([k for k,v in stats['by_weather'].items() if v > 0])}\")\n",
    "    print(f\"    - Scene types covered: {len([k for k,v in stats['by_scene'].items() if v > 0])}\")\n",
    "    print(f\"    - Time of day covered: {len([k for k,v in stats['by_timeofday'].items() if v > 0])}\")\n",
    "    print(f\"    - Attribute combinations: {len(stats['by_attribute_combo'])}\")\n",
    "\n",
    "print(f\"\\n{'='*90}\")\n",
    "print(f\"FULL DATASET TOTALS:\")\n",
    "print(f\"  Total images (ALL): {full_stats['total_images']:,}\")\n",
    "print(f\"  Total objects (ALL): {full_stats['total_objects']:,}\")\n",
    "print(f\"\\n  Representative samples info (for limited dataset creation):\")\n",
    "print(f\"    Samples selected: {full_stats['representative_samples']:,} ({(full_stats['representative_samples']/full_stats['total_images']*100):.2f}% of full)\")\n",
    "print(f\"    Objects in those samples: {full_stats['representative_objects']:,} ({(full_stats['representative_objects']/full_stats['total_objects']*100):.2f}% of full)\")\n",
    "print(f\"    Note: These samples were physically copied to create the limited dataset\")\n",
    "print(f\"  Number of classes: {len(class_names)}\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "# Display metadata summary for LIMITED dataset (3 files)\n",
    "if any(limited_metadata_by_split.values()):\n",
    "    print(\"\\n\\n\" + \"=\" * 90)\n",
    "    print(\"LIMITED DATASET METADATA (3 splits: train/val/test)\")\n",
    "    print(\"=\" * 90)\n",
    "    print(\"Note: Limited dataset contains ONLY the representative samples from full dataset\")\n",
    "    print(\"=\" * 90)\n",
    "    \n",
    "    # Aggregate statistics from limited dataset metadata (3 files)\n",
    "    limited_stats = {\n",
    "        'total_images': 0,\n",
    "        'total_selected': 0,\n",
    "        'by_split': {},\n",
    "        'total_objects_by_class': {}\n",
    "    }\n",
    "    \n",
    "    # Initialize class totals\n",
    "    for cls in class_names:\n",
    "        limited_stats['total_objects_by_class'][cls] = 0\n",
    "    \n",
    "    for split in ['train', 'val', 'test']:\n",
    "        if not limited_metadata_by_split[split]:\n",
    "            continue\n",
    "        \n",
    "        meta = limited_metadata_by_split[split]\n",
    "        stats = meta['statistics']\n",
    "        \n",
    "        # For limited dataset: use total_samples \n",
    "        total_images = meta['total_samples']\n",
    "        total_selected = meta['total_samples']  # All images are representative\n",
    "        \n",
    "        limited_stats['by_split'][split] = {\n",
    "            'images': total_images,\n",
    "            'selected': total_selected,\n",
    "            'objects_by_class': stats['by_class']\n",
    "        }\n",
    "        limited_stats['total_images'] += total_images\n",
    "        limited_stats['total_selected'] += total_selected\n",
    "        \n",
    "        # Aggregate object counts\n",
    "        for cls, count in stats['by_class'].items():\n",
    "            limited_stats['total_objects_by_class'][cls] += count\n",
    "        \n",
    "        print(f\"\\n{split.upper()} SPLIT\")\n",
    "        print(\"-\" * 90)\n",
    "        print(f\"  Source: {meta.get('data_source', 'N/A')}\")\n",
    "        print(f\"  Total images: {total_images:,} (all are representative samples)\")\n",
    "        print(f\"  Total objects detected: {sum(stats['by_class'].values()):,}\")\n",
    "        \n",
    "        # Use class_names if 'classes' not in metadata\n",
    "        num_classes = len(meta.get('classes', class_names))\n",
    "        classes_with_objects = len([k for k,v in stats['by_class'].items() if v > 0])\n",
    "        print(f\"  Classes with objects: {classes_with_objects}/{num_classes}\")\n",
    "    \n",
    "    print(f\"\\n{'='*90}\")\n",
    "    print(f\"LIMITED DATASET TOTALS:\")\n",
    "    print(f\"  Total images (all representative samples): {limited_stats['total_images']:,}\")\n",
    "    print(f\"  Total objects across all splits: {sum(limited_stats['total_objects_by_class'].values()):,}\")\n",
    "    print(f\"  Composition: Representative samples with comprehensive attribute coverage\")\n",
    "    print(\"=\" * 90)\n",
    "else:\n",
    "    limited_stats = None\n",
    "\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"\u2713 All 6 metadata files loaded successfully\")\n",
    "print(f\"  Full dataset metadata: 3 files (train/val/test_metadata.json)\")\n",
    "print(f\"    - Contains statistics for ALL 100K images\")\n",
    "print(f\"    - Tracks which samples were selected as representative\")\n",
    "print(f\"  Limited dataset metadata: 3 files (train/val/test_metadata.json)\")\n",
    "print(f\"    - Contains ONLY the representative samples (~2.3K)\")\n",
    "print(f\"    - IS the physical copy of representative samples from full dataset\")\n",
    "print(\"=\" * 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dd189f",
   "metadata": {
    "id": "17dd189f"
   },
   "source": [
    "## 4. Statistical Analysis and Visualizations\n",
    "\n",
    "### 4.1 Class Distribution Analysis\n",
    "\n",
    "**Comparison:** Full Dataset (ALL 100K images) vs Limited Dataset (Representative ~2.3K samples)\n",
    "\n",
    "**Important:** The limited dataset IS the representative samples - a physical copy of carefully selected diverse samples from the full dataset. There is no separate \"Full Dataset Representative\" - the representative samples exist ONLY in the limited dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4685f334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASS DISTRIBUTION ANALYSIS - Full Dataset (ALL) vs Limited Dataset (Representative)\n",
    "print(\"=\" * 90)\n",
    "print(\"CLASS DISTRIBUTION ANALYSIS - Full Dataset (ALL) vs Limited Dataset (Representative)\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "# Extract class statistics\n",
    "# Full dataset: Use ALL objects (by_class)\n",
    "# Limited dataset: IS the representative samples physically copied\n",
    "class_stats_full_all = {split: full_metadata_by_split[split]['statistics']['by_class'] \n",
    "                        for split in ['train', 'val', 'test'] if full_metadata_by_split[split]}\n",
    "\n",
    "class_stats_limited = {split: limited_metadata_by_split[split]['statistics']['by_class'] \n",
    "                       for split in ['train', 'val', 'test'] if limited_metadata_by_split[split]}\n",
    "\n",
    "print(f\"Full Dataset: {full_stats['total_images']:,} images, {full_stats['total_objects']:,} objects\")\n",
    "print(f\"Limited Dataset: {limited_stats['total_images']:,} images, {sum(limited_stats['total_objects_by_class'].values()):,} objects\")\n",
    "print(f\"Note: Limited dataset contains representative samples from full dataset ({(limited_stats['total_images']/full_stats['total_images']*100):.2f}%)\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "# Visualization 1: Side-by-side object counts per split\n",
    "fig, axes = plt.subplots(3, 2, figsize=(14, 10))\n",
    "fig.suptitle('Object Counts Per Class - Full Dataset (ALL) vs Limited Dataset (Representative)', fontsize=15, fontweight='bold')\n",
    "\n",
    "colors = {'full': '#3498db', 'limited': '#e74c3c'}\n",
    "\n",
    "for idx, split in enumerate(['train', 'val', 'test']):\n",
    "    # Full dataset (ALL images)\n",
    "    ax_full = axes[idx, 0]\n",
    "    if split in class_stats_full_all and class_stats_full_all[split]:\n",
    "        classes = list(class_stats_full_all[split].keys())\n",
    "        counts = list(class_stats_full_all[split].values())\n",
    "        \n",
    "        bars = ax_full.barh(classes, counts, color=colors['full'], alpha=0.8)\n",
    "        ax_full.set_xlabel('Total Objects', fontsize=11, fontweight='bold')\n",
    "        ax_full.set_title(f'Full Dataset - {split.upper()} (ALL)\\n({full_stats[\"by_split\"][split][\"images\"]:,} images)', \n",
    "                         fontsize=14, fontweight='bold')\n",
    "        ax_full.grid(axis='x', alpha=0.3)\n",
    "        ax_full.tick_params(axis='both', labelsize=10)\n",
    "        \n",
    "        for bar in bars:\n",
    "            width = bar.get_width()\n",
    "            if width > 0:\n",
    "                ax_full.text(width, bar.get_y() + bar.get_height()/2, \n",
    "                            f'{int(width):,}', ha='left', va='center', fontsize=9)\n",
    "    \n",
    "    # Limited dataset\n",
    "    ax_limited = axes[idx, 1]\n",
    "    if split in class_stats_limited and class_stats_limited[split]:\n",
    "        classes = list(class_stats_limited[split].keys())\n",
    "        counts = list(class_stats_limited[split].values())\n",
    "        \n",
    "        bars = ax_limited.barh(classes, counts, color=colors['limited'], alpha=0.8)\n",
    "        ax_limited.set_xlabel('Total Objects', fontsize=11, fontweight='bold')\n",
    "        ax_limited.set_title(f'Limited Dataset - {split.upper()}\\n({limited_stats[\"by_split\"][split][\"images\"]:,} images)', \n",
    "                            fontsize=14, fontweight='bold')\n",
    "        ax_limited.grid(axis='x', alpha=0.3)\n",
    "        ax_limited.tick_params(axis='both', labelsize=10)\n",
    "        \n",
    "        for bar in bars:\n",
    "            width = bar.get_width()\n",
    "            if width > 0:\n",
    "                ax_limited.text(width, bar.get_y() + bar.get_height()/2, \n",
    "                               f'{int(width):,}', ha='left', va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.99])\n",
    "plt.show()\n",
    "\n",
    "# Visualization 2: Direct comparison - Full (ALL) vs Limited for each split\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "fig.suptitle('Full Dataset (ALL) vs Limited Dataset (Representative) - Object Count Comparison by Split', fontsize=14, fontweight='bold')\n",
    "\n",
    "for idx, split in enumerate(['train', 'val', 'test']):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    full_counts = [class_stats_full_all[split].get(cls, 0) for cls in class_names]\n",
    "    limited_counts = [class_stats_limited[split].get(cls, 0) for cls in class_names]\n",
    "    \n",
    "    x = np.arange(len(class_names))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = ax.bar(x - width/2, full_counts, width, label='Full (ALL)', color=colors['full'], alpha=0.8)\n",
    "    bars2 = ax.bar(x + width/2, limited_counts, width, label='Limited (Representative)', color=colors['limited'], alpha=0.8)\n",
    "    \n",
    "    ax.set_xlabel('Classes', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Total Objects', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(f'{split.upper()} Split', fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(class_names, rotation=45, ha='right', fontsize=10)\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    ax.tick_params(axis='y', labelsize=10)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.99])\n",
    "plt.show()\n",
    "\n",
    "# Visualization 3: Total object counts across all splits - Full (ALL) vs Limited\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(13, 6))\n",
    "\n",
    "# Stacked comparison\n",
    "full_totals = list(full_stats['total_objects_by_class'].values())  # Use ALL objects\n",
    "limited_totals = list(limited_stats['total_objects_by_class'].values())\n",
    "\n",
    "x = np.arange(len(class_names))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax1.bar(x - width/2, full_totals, width, label='Full (ALL)', color=colors['full'], alpha=0.8)\n",
    "bars2 = ax1.bar(x + width/2, limited_totals, width, label='Limited (Representative)', color=colors['limited'], alpha=0.8)\n",
    "\n",
    "ax1.set_xlabel('Classes', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('Total Objects (All Splits)', fontsize=14, fontweight='bold')\n",
    "ax1.set_title('Total Object Counts - Full (ALL) vs Limited (Representative)', fontsize=14, fontweight='bold')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(class_names, rotation=45, ha='right', fontsize=9)\n",
    "ax1.legend(fontsize=9)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Percentage representation\n",
    "percentages = [(limited_totals[i] / full_totals[i] * 100) if full_totals[i] > 0 else 0 \n",
    "               for i in range(len(class_names))]\n",
    "\n",
    "bars = ax2.barh(class_names, percentages, color='#9b59b6', alpha=0.8)\n",
    "ax2.set_xlabel('Limited as % of Full (%)', fontsize=14, fontweight='bold')\n",
    "ax2.set_title('Limited Dataset (Representative) as % of Full Dataset (ALL)', fontsize=14, fontweight='bold')\n",
    "ax2.grid(axis='x', alpha=0.3)\n",
    "ax2.tick_params(axis='both', labelsize=11)\n",
    "\n",
    "for idx, bar in enumerate(bars):\n",
    "    width = bar.get_width()\n",
    "    if width > 0 and full_totals[idx] > 0:\n",
    "        ax2.text(width, bar.get_y() + bar.get_height()/2, \n",
    "                f'{width:.1f}%\\n({limited_totals[idx]:,}/{full_totals[idx]:,})', \n",
    "                ha='left', va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.99])\n",
    "plt.show()\n",
    "\n",
    "# Print detailed comparison summary\n",
    "print(\"\\nDetailed Class Distribution Summary:\")\n",
    "print(\"=\" * 90)\n",
    "print(f\"\\n{'Class':<20} | {'Full Dataset (ALL)':^50} | {'Limited (Representative)':^25}\")\n",
    "print(f\"{'':20} | {'Train':>10} {'Val':>10} {'Test':>10} {'Total':>15} | {'Total':>15}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "for cls in class_names:\n",
    "    # Use ALL objects from full dataset\n",
    "    full_train = class_stats_full_all['train'].get(cls, 0)\n",
    "    full_val = class_stats_full_all['val'].get(cls, 0)\n",
    "    full_test = class_stats_full_all['test'].get(cls, 0)\n",
    "    full_total = full_train + full_val + full_test\n",
    "    \n",
    "    limited_total = sum(class_stats_limited[split].get(cls, 0) for split in ['train', 'val', 'test'])\n",
    "    \n",
    "    if full_total > 0 or limited_total > 0:\n",
    "        pct = (limited_total / full_total * 100) if full_total > 0 else 0\n",
    "        print(f\"{cls:<20} | {full_train:>10,} {full_val:>10,} {full_test:>10,} {full_total:>15,} | {limited_total:>15,} ({pct:5.1f}%)\")\n",
    "\n",
    "print(\"-\" * 90)\n",
    "# Use ALL objects from full dataset for comparison\n",
    "full_grand_total = sum(full_stats['total_objects_by_class'].values())\n",
    "limited_grand_total = sum(limited_stats['total_objects_by_class'].values())\n",
    "grand_pct = (limited_grand_total / full_grand_total * 100) if full_grand_total > 0 else 0\n",
    "print(f\"{'TOTAL':<20} | {'':<10} {'':<10} {'':<10} {full_grand_total:>15,} | {limited_grand_total:>15,} ({grand_pct:5.1f}%)\")\n",
    "\n",
    "print(\"\\n\u2713 Class distribution analysis complete\")\n",
    "print(f\"Note: Limited dataset is a representative sample of {grand_pct:.1f}% of full dataset objects\")\n",
    "print(\"=\" * 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e894e51b",
   "metadata": {},
   "source": [
    "### 4.2 Attribute Distribution Analysis - Full Dataset (ALL) vs Limited Dataset (Representative)\n",
    "\n",
    "Analyze distribution of weather, scene, and time attributes. Limited dataset IS the representative samples from the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308a7050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive attribute distribution analysis - FULL DATASET (ALL) vs LIMITED DATASET (Representative)\n",
    "print(\"=\" * 90)\n",
    "print(\"ATTRIBUTE DISTRIBUTION ANALYSIS - Full Dataset (ALL) & Limited Dataset (Representative)\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "# Extract attribute statistics for FULL DATASET (ALL images)\n",
    "full_weather_stats = {split: {} for split in ['train', 'val', 'test']}\n",
    "full_scene_stats = {split: {} for split in ['train', 'val', 'test']}\n",
    "full_timeofday_stats = {split: {} for split in ['train', 'val', 'test']}\n",
    "\n",
    "# Extract attribute statistics for LIMITED DATASET (which IS the representative samples)\n",
    "limited_weather_stats = {split: {} for split in ['train', 'val', 'test']}\n",
    "limited_scene_stats = {split: {} for split in ['train', 'val', 'test']}\n",
    "limited_timeofday_stats = {split: {} for split in ['train', 'val', 'test']}\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    if full_metadata_by_split[split]:\n",
    "        stats = full_metadata_by_split[split]['statistics']\n",
    "        \n",
    "        # Full dataset attributes (ALL images)\n",
    "        if 'full_dataset_attributes' in stats:\n",
    "            full_weather_stats[split] = stats['full_dataset_attributes'].get('by_weather', {})\n",
    "            full_scene_stats[split] = stats['full_dataset_attributes'].get('by_scene', {})\n",
    "            full_timeofday_stats[split] = stats['full_dataset_attributes'].get('by_timeofday', {})\n",
    "    \n",
    "    # Limited dataset attributes - NEW STRUCTURE: list format [weather_dict, scene_dict, timeofday_dict]\n",
    "    if limited_metadata_by_split[split]:\n",
    "        stats = limited_metadata_by_split[split]['statistics']\n",
    "        if 'attributes' in stats and isinstance(stats['attributes'], list) and len(stats['attributes']) >= 3:\n",
    "            limited_weather_stats[split] = stats['attributes'][0]  # First element is weather\n",
    "            limited_scene_stats[split] = stats['attributes'][1]    # Second is scene\n",
    "            limited_timeofday_stats[split] = stats['attributes'][2]  # Third is timeofday\n",
    "\n",
    "print(\"\\nFull Dataset (ALL) Attribute Coverage:\")\n",
    "for split in ['train', 'val', 'test']:\n",
    "    if full_weather_stats[split]:\n",
    "        print(f\"  {split.upper()}: {sum(full_weather_stats[split].values()):,} images with attributes\")\n",
    "\n",
    "print(\"\\nLimited Dataset (Representative) Attribute Coverage:\")\n",
    "for split in ['train', 'val', 'test']:\n",
    "    if limited_weather_stats[split]:\n",
    "        print(f\"  {split.upper()}: {sum(limited_weather_stats[split].values()):,} samples\")\n",
    "\n",
    "print(\"=\" * 90)\n",
    "\n",
    "# Visualization 1: Weather distribution - Full Dataset (ALL) vs Limited Dataset (Representative)\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 9))\n",
    "fig.suptitle('Weather Attribute Distribution - Full Dataset (ALL) vs Limited Dataset (Representative)', fontsize=14, fontweight='bold')\n",
    "\n",
    "colors_splits = ['#3498db', '#e67e22', '#2ecc71']\n",
    "\n",
    "for idx, split in enumerate(['train', 'val', 'test']):\n",
    "    # Full dataset (ALL)\n",
    "    ax_full = axes[0, idx]\n",
    "    if full_weather_stats[split]:\n",
    "        weather_types = sorted(full_weather_stats[split].keys())\n",
    "        counts = [full_weather_stats[split][w] for w in weather_types]\n",
    "        \n",
    "        bars = ax_full.barh(weather_types, counts, color=colors_splits[idx], alpha=0.8)\n",
    "        ax_full.set_xlabel('Number of Images', fontsize=12, fontweight='bold')\n",
    "        ax_full.set_title(f'Full (ALL) - {split.upper()}\\n({sum(counts):,} images)', fontsize=14, fontweight='bold')\n",
    "        ax_full.grid(axis='x', alpha=0.3)\n",
    "        ax_full.tick_params(axis='both', labelsize=11)\n",
    "        \n",
    "        for bar in bars:\n",
    "            width = bar.get_width()\n",
    "            if width > 0:\n",
    "                ax_full.text(width, bar.get_y() + bar.get_height()/2, \n",
    "                           f'{int(width):,}', ha='left', va='center', fontsize=10)\n",
    "    \n",
    "    # Limited dataset (Representative)\n",
    "    ax_limited = axes[1, idx]\n",
    "    if limited_weather_stats[split]:\n",
    "        weather_types = sorted(limited_weather_stats[split].keys())\n",
    "        counts = [limited_weather_stats[split][w] for w in weather_types]\n",
    "        \n",
    "        bars = ax_limited.barh(weather_types, counts, color=colors_splits[idx], alpha=0.8)\n",
    "        ax_limited.set_xlabel('Number of Samples', fontsize=12, fontweight='bold')\n",
    "        ax_limited.set_title(f'Limited (Representative) - {split.upper()}\\n({sum(counts):,} samples)', fontsize=14, fontweight='bold')\n",
    "        ax_limited.grid(axis='x', alpha=0.3)\n",
    "        ax_limited.tick_params(axis='both', labelsize=11)\n",
    "        \n",
    "        for bar in bars:\n",
    "            width = bar.get_width()\n",
    "            if width > 0:\n",
    "                ax_limited.text(width, bar.get_y() + bar.get_height()/2, \n",
    "                           f'{int(width):,}', ha='left', va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.99])\n",
    "plt.show()\n",
    "\n",
    "# Visualization 2: Scene distribution - Full Dataset (ALL) vs Limited Dataset (Representative)\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 9))\n",
    "fig.suptitle('Scene Attribute Distribution - Full Dataset (ALL) vs Limited Dataset (Representative)', fontsize=14, fontweight='bold')\n",
    "\n",
    "for idx, split in enumerate(['train', 'val', 'test']):\n",
    "    # Full dataset (ALL)\n",
    "    ax_full = axes[0, idx]\n",
    "    if full_scene_stats[split]:\n",
    "        scene_types = sorted(full_scene_stats[split].keys())\n",
    "        counts = [full_scene_stats[split][s] for s in scene_types]\n",
    "        \n",
    "        bars = ax_full.barh(scene_types, counts, color=colors_splits[idx], alpha=0.8)\n",
    "        ax_full.set_xlabel('Number of Images', fontsize=12, fontweight='bold')\n",
    "        ax_full.set_title(f'Full (ALL) - {split.upper()}\\n({sum(counts):,} images)', fontsize=14, fontweight='bold')\n",
    "        ax_full.grid(axis='x', alpha=0.3)\n",
    "        ax_full.tick_params(axis='both', labelsize=11)\n",
    "        \n",
    "        for bar in bars:\n",
    "            width = bar.get_width()\n",
    "            if width > 0:\n",
    "                ax_full.text(width, bar.get_y() + bar.get_height()/2, \n",
    "                           f'{int(width):,}', ha='left', va='center', fontsize=10)\n",
    "    \n",
    "    # Limited dataset (Representative)\n",
    "    ax_limited = axes[1, idx]\n",
    "    if limited_scene_stats[split]:\n",
    "        scene_types = sorted(limited_scene_stats[split].keys())\n",
    "        counts = [limited_scene_stats[split][s] for s in scene_types]\n",
    "        \n",
    "        bars = ax_limited.barh(scene_types, counts, color=colors_splits[idx], alpha=0.8)\n",
    "        ax_limited.set_xlabel('Number of Samples', fontsize=12, fontweight='bold')\n",
    "        ax_limited.set_title(f'Limited (Representative) - {split.upper()}\\n({sum(counts):,} samples)', fontsize=14, fontweight='bold')\n",
    "        ax_limited.grid(axis='x', alpha=0.3)\n",
    "        ax_limited.tick_params(axis='both', labelsize=11)\n",
    "        \n",
    "        for bar in bars:\n",
    "            width = bar.get_width()\n",
    "            if width > 0:\n",
    "                ax_limited.text(width, bar.get_y() + bar.get_height()/2, \n",
    "                           f'{int(width):,}', ha='left', va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.99])\n",
    "plt.show()\n",
    "\n",
    "# Visualization 3: Time of Day distribution - Full Dataset (ALL) vs Limited Dataset (Representative)\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "fig.suptitle('Time of Day Attribute Distribution - Full Dataset (ALL) vs Limited Dataset (Representative)', fontsize=14, fontweight='bold')\n",
    "\n",
    "for idx, split in enumerate(['train', 'val', 'test']):\n",
    "    # Full dataset (ALL)\n",
    "    ax_full = axes[0, idx]\n",
    "    if full_timeofday_stats[split]:\n",
    "        timeofday_types = sorted(full_timeofday_stats[split].keys())\n",
    "        counts = [full_timeofday_stats[split][t] for t in timeofday_types]\n",
    "        \n",
    "        bars = ax_full.barh(timeofday_types, counts, color=colors_splits[idx], alpha=0.8)\n",
    "        ax_full.set_xlabel('Number of Images', fontsize=12, fontweight='bold')\n",
    "        ax_full.set_title(f'Full (ALL) - {split.upper()}\\n({sum(counts):,} images)', fontsize=14, fontweight='bold')\n",
    "        ax_full.grid(axis='x', alpha=0.3)\n",
    "        ax_full.tick_params(axis='both', labelsize=11)\n",
    "        \n",
    "        for bar in bars:\n",
    "            width = bar.get_width()\n",
    "            if width > 0:\n",
    "                ax_full.text(width, bar.get_y() + bar.get_height()/2, \n",
    "                           f'{int(width):,}', ha='left', va='center', fontsize=10)\n",
    "    \n",
    "    # Limited dataset (Representative)\n",
    "    ax_limited = axes[1, idx]\n",
    "    if limited_timeofday_stats[split]:\n",
    "        timeofday_types = sorted(limited_timeofday_stats[split].keys())\n",
    "        counts = [limited_timeofday_stats[split][t] for t in timeofday_types]\n",
    "        \n",
    "        bars = ax_limited.barh(timeofday_types, counts, color=colors_splits[idx], alpha=0.8)\n",
    "        ax_limited.set_xlabel('Number of Samples', fontsize=12, fontweight='bold')\n",
    "        ax_limited.set_title(f'Limited (Representative) - {split.upper()}\\n({sum(counts):,} samples)', fontsize=14, fontweight='bold')\n",
    "        ax_limited.grid(axis='x', alpha=0.3)\n",
    "        ax_limited.tick_params(axis='both', labelsize=11)\n",
    "        \n",
    "        for bar in bars:\n",
    "            width = bar.get_width()\n",
    "            if width > 0:\n",
    "                ax_limited.text(width, bar.get_y() + bar.get_height()/2, \n",
    "                           f'{int(width):,}', ha='left', va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.99])\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"ATTRIBUTE DISTRIBUTION SUMMARY\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "print(\"\\nWeather Distribution:\")\n",
    "print(f\"{'Attribute Value':<20} | {'Full (ALL) Train':>15} {'Val':>12} {'Test':>12} | {'Limited Train':>15} {'Val':>12} {'Test':>12}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "all_weather = set()\n",
    "for split_data in full_weather_stats.values():\n",
    "    all_weather.update(split_data.keys())\n",
    "for split_data in limited_weather_stats.values():\n",
    "    all_weather.update(split_data.keys())\n",
    "\n",
    "for weather in sorted(all_weather):\n",
    "    full_train = full_weather_stats['train'].get(weather, 0)\n",
    "    full_val = full_weather_stats['val'].get(weather, 0)\n",
    "    full_test = full_weather_stats['test'].get(weather, 0)\n",
    "    limited_train = limited_weather_stats['train'].get(weather, 0)\n",
    "    limited_val = limited_weather_stats['val'].get(weather, 0)\n",
    "    limited_test = limited_weather_stats['test'].get(weather, 0)\n",
    "    \n",
    "    print(f\"{weather:<20} | {full_train:>15,} {full_val:>12,} {full_test:>12,} | {limited_train:>15,} {limited_val:>12,} {limited_test:>12,}\")\n",
    "\n",
    "print(\"\\n\u2713 Attribute distribution analysis complete\")\n",
    "print(\"Note: Limited dataset IS the representative sample from full dataset\")\n",
    "print(\"=\" * 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004fe988",
   "metadata": {},
   "source": [
    "### 4.3 Dataset Comparison - Full vs Limited\n",
    "\n",
    "Compare statistics between full and limited datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1aed62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive dataset comparison - Full vs Limited using CORRECT metadata\n",
    "print(\"=\" * 90)\n",
    "print(\"DATASET COMPARISON - FULL VS LIMITED\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "if limited_stats:\n",
    "    # Prepare data\n",
    "    splits = ['train', 'val', 'test']\n",
    "    full_images = [full_stats['by_split'][split]['images'] for split in splits]\n",
    "    limited_images = [limited_stats['by_split'][split]['images'] for split in splits]\n",
    "    full_objects = [sum(full_stats['by_split'][split]['objects_by_class'].values()) for split in splits]\n",
    "    limited_objects = [sum(limited_stats['by_split'][split]['objects_by_class'].values()) for split in splits]\n",
    "    \n",
    "    # Visualization: Percentage comparison (cleaner than raw counts)\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(13, 5))\n",
    "    \n",
    "    # Image percentage\n",
    "    img_percentages = [(limited_images[i] / full_images[i] * 100) for i in range(len(splits))]\n",
    "    bars = ax1.barh(splits, img_percentages, color=['#1f77b4', '#ff7f0e', '#2ca02c'], alpha=0.8)\n",
    "    ax1.set_xlabel('Percentage (%)', fontsize=12, fontweight='bold')\n",
    "    ax1.set_ylabel('Split', fontsize=12, fontweight='bold')\n",
    "    ax1.set_title('Limited Dataset Images as % of Full Dataset', fontsize=13, fontweight='bold')\n",
    "    ax1.grid(axis='x', alpha=0.3)\n",
    "    ax1.tick_params(axis='both', labelsize=11)\n",
    "    \n",
    "    for idx, bar in enumerate(bars):\n",
    "        width = bar.get_width()\n",
    "        ax1.text(width, bar.get_y() + bar.get_height()/2, \n",
    "               f'{width:.2f}%\\n({limited_images[idx]:,}/{full_images[idx]:,})', \n",
    "               ha='left', va='center', fontsize=8, fontweight='bold')\n",
    "    \n",
    "    # Object percentage\n",
    "    obj_percentages = [(limited_objects[i] / full_objects[i] * 100) if full_objects[i] > 0 else 0 \n",
    "                       for i in range(len(splits))]\n",
    "    bars = ax2.barh(splits, obj_percentages, color=['#1f77b4', '#ff7f0e', '#2ca02c'], alpha=0.8)\n",
    "    ax2.set_xlabel('Percentage (%)', fontsize=12, fontweight='bold')\n",
    "    ax2.set_ylabel('Split', fontsize=12, fontweight='bold')\n",
    "    ax2.set_title('Limited Dataset Objects as % of Full Dataset', fontsize=13, fontweight='bold')\n",
    "    ax2.grid(axis='x', alpha=0.3)\n",
    "    ax2.tick_params(axis='both', labelsize=11)\n",
    "    \n",
    "    for idx, bar in enumerate(bars):\n",
    "        width = bar.get_width()\n",
    "        ax2.text(width, bar.get_y() + bar.get_height()/2, \n",
    "               f'{width:.2f}%\\n({limited_objects[idx]:,}/{full_objects[idx]:,})', \n",
    "               ha='left', va='center', fontsize=8, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.99])\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary (concise - detailed counts already in Section 3.2 & 4.1)\n",
    "    full_total_obj = sum(full_stats['total_objects_by_class'].values())\n",
    "    limited_total_obj = sum(limited_stats['total_objects_by_class'].values())\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 90)\n",
    "    print(\"COMPARISON SUMMARY\")\n",
    "    print(\"=\" * 90)\n",
    "    print(f\"Dataset Reduction: {full_stats['total_images'] / limited_stats['total_images']:.1f}x smaller\")\n",
    "    print(f\"Object Coverage: {(limited_total_obj/full_total_obj*100):.1f}% of full dataset objects\")\n",
    "    print(f\"Object Density: {limited_total_obj/limited_stats['total_images']:.1f} objects/image (limited) vs \"\n",
    "          f\"{full_total_obj/full_stats['total_images']:.1f} objects/image (full)\")\n",
    "    print(\"=\" * 90)\n",
    "else:\n",
    "    print(\"\u26a0 Limited dataset not available for comparison\")\n",
    "\n",
    "print(\"\\n\u2713 Dataset comparison complete\")\n",
    "print(\"=\" * 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21e1817",
   "metadata": {},
   "source": [
    "## 5. Visualizations\n",
    "\n",
    "### 5.1 Sample Images with Annotations\n",
    "\n",
    "Representative samples showing diverse attributes (weather, scene, time) for each class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8faf3fa",
   "metadata": {
    "id": "f8faf3fa"
   },
   "source": [
    "### 5.2 Complex Multi-Object Scenes\n",
    "\n",
    "Examples of images with multiple objects and diverse classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446a1bd1",
   "metadata": {
    "id": "446a1bd1",
    "outputId": "86505baf-aabe-4958-d4ef-c06318367682"
   },
   "outputs": [],
   "source": [
    "# Helper function to draw bounding boxes - can filter by target class\n",
    "def draw_yolo_boxes(img_path, label_path, class_names, target_class_id=None):\n",
    "    \"\"\"\n",
    "    Draw bounding boxes on image with class labels.\n",
    "    \n",
    "    Args:\n",
    "        img_path: Path to image\n",
    "        label_path: Path to label file\n",
    "        class_names: List of class names\n",
    "        target_class_id: If specified, only draw boxes for this class. If None, draw all classes.\n",
    "    \"\"\"\n",
    "    if not img_path.exists():\n",
    "        return None, 0\n",
    "    \n",
    "    img = cv2.imread(str(img_path))\n",
    "    if img is None:\n",
    "        return None, 0\n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    h, w = img.shape[:2]\n",
    "    \n",
    "    num_objects = 0\n",
    "    if label_path.exists():\n",
    "        with open(label_path, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) < 5:\n",
    "                    continue\n",
    "                \n",
    "                class_id = int(parts[0])\n",
    "                \n",
    "                # Skip if target_class_id is specified and this isn't it\n",
    "                if target_class_id is not None and class_id != target_class_id:\n",
    "                    continue\n",
    "                \n",
    "                x_center, y_center, width, height = map(float, parts[1:5])\n",
    "                \n",
    "                # Convert to pixel coordinates\n",
    "                x1 = int((x_center - width / 2) * w)\n",
    "                y1 = int((y_center - height / 2) * h)\n",
    "                x2 = int((x_center + width / 2) * w)\n",
    "                y2 = int((y_center + height / 2) * h)\n",
    "                \n",
    "                # Draw box\n",
    "                colors = plt.cm.tab10.colors\n",
    "                color = tuple(int(c * 255) for c in colors[class_id % len(colors)])\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), color, 3)\n",
    "                \n",
    "                # Add class label only\n",
    "                label = class_names[class_id]\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                (text_w, text_h), _ = cv2.getTextSize(label, font, 0.7, 2)\n",
    "                cv2.rectangle(img, (x1, y1 - text_h - 10), (x1 + text_w + 10, y1), color, -1)\n",
    "                cv2.putText(img, label, (x1 + 5, y1 - 5), font, 0.7, (255, 255, 255), 2)\n",
    "                \n",
    "                num_objects += 1\n",
    "    \n",
    "    return img, num_objects\n",
    "\n",
    "\n",
    "# Organize samples by class from metadata\n",
    "print(\"=\" * 90)\n",
    "print(\"ORGANIZING REPRESENTATIVE SAMPLES FROM METADATA\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "viz_images_dir = LIMITED_DATASET_ROOT / 'images' if LIMITED_DATASET_ROOT.exists() else FULL_DATASET_ROOT / 'images'\n",
    "viz_labels_dir = LIMITED_DATASET_ROOT / 'labels' if LIMITED_DATASET_ROOT.exists() else FULL_DATASET_ROOT / 'labels'\n",
    "\n",
    "samples_by_class = {class_id: [] for class_id in range(len(class_names))}\n",
    "\n",
    "# Use performance_analysis data (works for both full and limited datasets)\n",
    "performance_source = limited_performance_by_split if any(limited_performance_by_split.values()) else full_performance_by_split\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    if not performance_source[split]:\n",
    "        continue\n",
    "    \n",
    "    perf_data = performance_source[split]\n",
    "    \n",
    "    # Group images by class from performance data\n",
    "    for img_info in perf_data['images']:\n",
    "        basename = img_info['basename']\n",
    "        classes_present = img_info['classes_present']\n",
    "        \n",
    "        # Add this image to samples for each class it contains\n",
    "        for class_name in classes_present:\n",
    "            if class_name in class_names:\n",
    "                class_id = class_names.index(class_name)\n",
    "                \n",
    "                # Limit samples per class per split\n",
    "                if len([s for s in samples_by_class[class_id] if s['split'] == split]) >= 5:\n",
    "                    continue\n",
    "                \n",
    "                # Find image file\n",
    "                img_path = None\n",
    "                for ext in ['.jpg', '.png', '.jpeg']:\n",
    "                    test_path = viz_images_dir / split / f\"{basename}{ext}\"\n",
    "                    if test_path.exists():\n",
    "                        img_path = test_path\n",
    "                        break\n",
    "                \n",
    "                label_path = viz_labels_dir / split / f\"{basename}.txt\"\n",
    "                \n",
    "                if img_path and label_path.exists():\n",
    "                    samples_by_class[class_id].append({\n",
    "                        'img_path': img_path,\n",
    "                        'label_path': label_path,\n",
    "                        'split': split\n",
    "                    })\n",
    "\n",
    "print(f\"\u2713 Organized samples for visualization\")\n",
    "\n",
    "# Display samples for each class - ONLY ANNOTATE TARGET CLASS\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"VISUALIZING REPRESENTATIVE SAMPLES PER CLASS\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "for class_id, class_name in enumerate(class_names):\n",
    "    samples = samples_by_class[class_id]\n",
    "    \n",
    "    if not samples:\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\nClass: {class_name.upper()}\")\n",
    "    \n",
    "    num_samples = min(len(samples), 9)  # Max 9 samples (3x3 grid)\n",
    "    cols = 3\n",
    "    rows = (num_samples + cols - 1) // cols\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(14, 3 * rows))\n",
    "    \n",
    "    if rows == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    fig.suptitle(f\"Class: {class_name}\", fontsize=14, fontweight='bold', y=0.998)\n",
    "    \n",
    "    for idx, sample in enumerate(samples[:num_samples]):\n",
    "        row = idx // cols\n",
    "        col = idx % cols\n",
    "        ax = axes[row, col]\n",
    "        \n",
    "        # ONLY draw boxes for this specific class\n",
    "        img_with_boxes, num_objects = draw_yolo_boxes(\n",
    "            sample['img_path'], \n",
    "            sample['label_path'], \n",
    "            class_names,\n",
    "            target_class_id=class_id  # Filter to only this class\n",
    "        )\n",
    "        \n",
    "        if img_with_boxes is not None:\n",
    "            ax.imshow(img_with_boxes)\n",
    "            ax.set_title(\n",
    "                f\"{sample['img_path'].name}\\nSplit: {sample['split'].upper()}\", \n",
    "                fontsize=10, pad=3\n",
    "            )\n",
    "        else:\n",
    "            ax.text(0.5, 0.5, 'Image not found', ha='center', va='center', fontsize=10)\n",
    "        \n",
    "        ax.axis('off')\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for idx in range(num_samples, rows * cols):\n",
    "        row = idx // cols\n",
    "        col = idx % cols\n",
    "        axes[row, col].axis('off')\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.99])\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"\u2713 Visualization complete\")\n",
    "print(\"=\" * 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07f1a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find images with multiple objects\n",
    "print(\"=\" * 90)\n",
    "print(\"FINDING COMPLEX MULTI-OBJECT SCENES\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "multi_object_samples = []\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    split_labels_dir = viz_labels_dir / split\n",
    "    \n",
    "    if not split_labels_dir.exists():\n",
    "        continue\n",
    "    \n",
    "    for label_file in split_labels_dir.glob(\"*.txt\"):\n",
    "        with open(label_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        if len(lines) >= 5:  # At least 5 objects\n",
    "            # Count unique classes\n",
    "            classes_in_image = set()\n",
    "            for line in lines:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 5:\n",
    "                    classes_in_image.add(int(parts[0]))\n",
    "            \n",
    "            # Find corresponding image\n",
    "            img_path = None\n",
    "            for ext in ['.jpg', '.png', '.jpeg']:\n",
    "                test_path = viz_images_dir / split / f\"{label_file.stem}{ext}\"\n",
    "                if test_path.exists():\n",
    "                    img_path = test_path\n",
    "                    break\n",
    "            \n",
    "            if img_path:\n",
    "                multi_object_samples.append({\n",
    "                    'img_path': img_path,\n",
    "                    'label_path': label_file,\n",
    "                    'num_objects': len(lines),\n",
    "                    'num_classes': len(classes_in_image),\n",
    "                    'split': split\n",
    "                })\n",
    "\n",
    "# Sort by diversity (more classes first), then by number of objects\n",
    "multi_object_samples.sort(key=lambda x: (x['num_classes'], x['num_objects']), reverse=True)\n",
    "\n",
    "print(f\"\u2713 Found {len(multi_object_samples)} images with 5+ objects\")\n",
    "\n",
    "# Display top 5 most complex scenes - ANNOTATE ALL CLASSES\n",
    "num_to_display = min(5, len(multi_object_samples))\n",
    "\n",
    "print(f\"\\nDisplaying {num_to_display} most complex scenes:\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "for i in range(num_to_display):\n",
    "    sample = multi_object_samples[i]\n",
    "    \n",
    "    # Draw ALL classes in multi-object scenes (target_class_id=None)\n",
    "    img_with_boxes, num_objects = draw_yolo_boxes(\n",
    "        sample['img_path'],\n",
    "        sample['label_path'],\n",
    "        class_names,\n",
    "        target_class_id=None  # Show all classes\n",
    "    )\n",
    "    \n",
    "    if img_with_boxes is not None:\n",
    "        # Get class distribution\n",
    "        class_counts = Counter()\n",
    "        with open(sample['label_path'], 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 5:\n",
    "                    class_counts[int(parts[0])] += 1\n",
    "        \n",
    "        class_summary = \", \".join([\n",
    "            f\"{class_names[cid]}({cnt})\" \n",
    "            for cid, cnt in sorted(class_counts.items())\n",
    "        ])\n",
    "        \n",
    "        # Display\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(14, 8))\n",
    "        ax.imshow(img_with_boxes)\n",
    "        ax.set_title(\n",
    "            f\"Scene #{i+1} | Total Objects: {num_objects} | Unique Classes: {sample['num_classes']} | \"\n",
    "            f\"Split: {sample['split'].upper()}\\n{class_summary}\",\n",
    "            fontsize=14, fontweight='bold', pad=12\n",
    "        )\n",
    "        ax.axis('off')\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.99])\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\u2713 Scene #{i+1}: {num_objects} objects, {sample['num_classes']} unique classes\")\n",
    "\n",
    "print(\"=\" * 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011e41a1",
   "metadata": {
    "id": "011e41a1"
   },
   "source": [
    "## 6. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc56947b",
   "metadata": {
    "id": "bc56947b",
    "outputId": "4388155d-a388-415a-e3cd-9474b56e93d0"
   },
   "outputs": [],
   "source": [
    "print(\"=\" * 90)\n",
    "print(\"BDD100K DATASET SUMMARY\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "print(\"\\n1. CLASSES\")\n",
    "print(\"-\" * 90)\n",
    "for idx, class_name in enumerate(class_names):\n",
    "    print(f\"  {idx}. {class_name}\")\n",
    "\n",
    "print(\"\\n2. METADATA FILES\")\n",
    "print(\"-\" * 90)\n",
    "print(f\"  Full dataset: {FULL_DATASET_ROOT / 'representative_json'}\")\n",
    "for split in ['train', 'val', 'test']:\n",
    "    print(f\"    - {split}_metadata.json\")\n",
    "if limited_stats:\n",
    "    print(f\"  Limited dataset: {LIMITED_DATASET_ROOT / 'representative_json'}\")\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        print(f\"    - {split}_metadata.json\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"\u2705 Dataset exploration complete!\")\n",
    "print(\"=\" * 90)\n",
    "print(\"\\nNotes:\")\n",
    "print(\"  - All file counts and statistics shown in Section 3.2\")\n",
    "print(\"  - Integrity checks (image-label matching) performed during dataset preparation\")\n",
    "print(\"  - Statistics loaded from pre-computed metadata files\")\n",
    "print(\"  - Visualizations use representative samples with comprehensive coverage\")\n",
    "print(\"  - Dataset ready for YOLO training!\")\n",
    "print(\"=\" * 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ea03ca",
   "metadata": {},
   "source": [
    "## 6. Per-Image Attribute Data\n",
    "\n",
    "Performance metadata containing per-image attributes and class information for model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80564ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample of per-image performance data\n",
    "print(\"=\" * 90)\n",
    "print(\"PER-IMAGE ATTRIBUTE DATA (Performance Analysis Metadata)\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "# Check if performance data is available\n",
    "if full_performance_by_split.get('test'):\n",
    "    perf_data = full_performance_by_split['test']\n",
    "    \n",
    "    print(f\"\\nFull Dataset - Test Split:\")\n",
    "    print(f\"  Total images: {perf_data['total_images']}\")\n",
    "    print(f\"  Generation date: {perf_data['generation_date']}\")\n",
    "    \n",
    "    # Show sample entries\n",
    "    print(f\"\\nSample entries (first 5 images):\")\n",
    "    print(\"-\" * 90)\n",
    "    \n",
    "    for i, img_data in enumerate(perf_data['images'][:5]):\n",
    "        print(f\"\\n{i+1}. Image: {img_data['basename']}\")\n",
    "        print(f\"   Weather: {img_data['weather']}\")\n",
    "        print(f\"   Scene: {img_data['scene']}\")\n",
    "        print(f\"   Time of day: {img_data['timeofday']}\")\n",
    "        print(f\"   Classes present: {', '.join(img_data['classes_present']) if img_data['classes_present'] else 'None'}\")\n",
    "        print(f\"   Total objects: {img_data['total_objects']}\")\n",
    "        if img_data['objects_per_class']:\n",
    "            print(f\"   Objects per class: {dict(list(img_data['objects_per_class'].items())[:3])}\")\n",
    "    \n",
    "    # Statistics about attributes\n",
    "    print(\"\\n\" + \"=\" * 90)\n",
    "    print(\"ATTRIBUTE COVERAGE IN PERFORMANCE DATA\")\n",
    "    print(\"=\" * 90)\n",
    "    \n",
    "    weather_count = {}\n",
    "    scene_count = {}\n",
    "    timeofday_count = {}\n",
    "    \n",
    "    for img_data in perf_data['images']:\n",
    "        weather = img_data['weather']\n",
    "        scene = img_data['scene']\n",
    "        timeofday = img_data['timeofday']\n",
    "        \n",
    "        weather_count[weather] = weather_count.get(weather, 0) + 1\n",
    "        scene_count[scene] = scene_count.get(scene, 0) + 1\n",
    "        timeofday_count[timeofday] = timeofday_count.get(timeofday, 0) + 1\n",
    "    \n",
    "    print(f\"\\nWeather conditions: {len(weather_count)} types\")\n",
    "    for weather, count in sorted(weather_count.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"  {weather}: {count} images\")\n",
    "    \n",
    "    print(f\"\\nScene types: {len(scene_count)} types\")\n",
    "    for scene, count in sorted(scene_count.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"  {scene}: {count} images\")\n",
    "    \n",
    "    print(f\"\\nTime of day: {len(timeofday_count)} types\")\n",
    "    for timeofday, count in sorted(timeofday_count.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"  {timeofday}: {count} images\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 90)\n",
    "    print(\"\u2713 Performance metadata ready for YOLO model evaluation\")\n",
    "    print(\"  Use this data in yolo_test notebook for attribute-based performance analysis\")\n",
    "    print(\"=\" * 90)\n",
    "    \n",
    "else:\n",
    "    print(\"\\n\u26a0\ufe0f  Performance data not available for test split\")\n",
    "    print(\"Run: python3 process_bdd100k_to_yolo_dataset.py\")\n",
    "\n",
    "# Check limited dataset performance data\n",
    "if limited_performance_by_split.get('test'):\n",
    "    perf_data = limited_performance_by_split['test']\n",
    "    \n",
    "    print(f\"\\n\\nLimited Dataset - Test Split:\")\n",
    "    print(f\"  Total images: {perf_data['total_images']}\")\n",
    "    print(f\"  Generation date: {perf_data['generation_date']}\")\n",
    "    \n",
    "    # Show sample entries\n",
    "    print(f\"\\nSample entries (first 5 representative images):\")\n",
    "    print(\"-\" * 90)\n",
    "    \n",
    "    for i, img_data in enumerate(perf_data['images'][:5]):\n",
    "        print(f\"\\n{i+1}. Image: {img_data['basename']}\")\n",
    "        print(f\"   Weather: {img_data['weather']}\")\n",
    "        print(f\"   Scene: {img_data['scene']}\")\n",
    "        print(f\"   Time of day: {img_data['timeofday']}\")\n",
    "        print(f\"   Classes present: {', '.join(img_data['classes_present']) if img_data['classes_present'] else 'None'}\")\n",
    "        print(f\"   Total objects: {img_data['total_objects']}\")\n",
    "        if img_data['objects_per_class']:\n",
    "            print(f\"   Objects per class: {dict(list(img_data['objects_per_class'].items())[:3])}\")\n",
    "    \n",
    "    # Statistics about attributes\n",
    "    print(\"\\n\" + \"=\" * 90)\n",
    "    print(\"ATTRIBUTE COVERAGE IN LIMITED DATASET PERFORMANCE DATA\")\n",
    "    print(\"=\" * 90)\n",
    "    \n",
    "    weather_count = {}\n",
    "    scene_count = {}\n",
    "    timeofday_count = {}\n",
    "    \n",
    "    for img_data in perf_data['images']:\n",
    "        weather = img_data['weather']\n",
    "        scene = img_data['scene']\n",
    "        timeofday = img_data['timeofday']\n",
    "        \n",
    "        weather_count[weather] = weather_count.get(weather, 0) + 1\n",
    "        scene_count[scene] = scene_count.get(scene, 0) + 1\n",
    "        timeofday_count[timeofday] = timeofday_count.get(timeofday, 0) + 1\n",
    "    \n",
    "    print(f\"\\nWeather conditions: {len(weather_count)} types\")\n",
    "    for weather, count in sorted(weather_count.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"  {weather}: {count} representative samples\")\n",
    "    \n",
    "    print(f\"\\nScene types: {len(scene_count)} types\")\n",
    "    for scene, count in sorted(scene_count.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"  {scene}: {count} representative samples\")\n",
    "    \n",
    "    print(f\"\\nTime of day: {len(timeofday_count)} types\")\n",
    "    for timeofday, count in sorted(timeofday_count.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"  {timeofday}: {count} representative samples\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 90)\n",
    "    print(\"\u2713 Limited dataset performance metadata ready for YOLO model evaluation\")\n",
    "    print(\"  Use this data in yolo_test notebook for attribute-based performance analysis\")\n",
    "    print(\"  Representative samples ensure comprehensive coverage across all attributes\")\n",
    "    print(\"=\" * 90)\n",
    "else:\n",
    "    print(\"\\n\\n\u26a0\ufe0f  Performance data not available for limited dataset test split\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b7973a",
   "metadata": {
    "id": "c3b7973a"
   },
   "source": [
    "## Exploration Complete\n",
    "\n",
    "This notebook has successfully:\n",
    "1. \u2713 Loaded metadata from both full and limited datasets with complete file counts (Section 3.2)\n",
    "2. \u2713 Displayed comprehensive pre-computed statistics from metadata files for both datasets\n",
    "3. \u2713 Visualized class distribution across splits (train/val/test) for both datasets (Section 4.1)\n",
    "4. \u2713 Analyzed attribute distributions (weather, scene, time) across splits (Section 4.2)\n",
    "5. \u2713 Created comparison charts between full and limited datasets (Section 4.3)\n",
    "6. \u2713 Visualized representative samples per class with **only target class annotated** (Section 5.1)\n",
    "7. \u2713 Showed complex multi-object scenes with **all classes annotated** (Section 5.2)\n",
    "8. \u2713 Loaded per-image performance metadata with attributes and class information (Section 6)\n",
    "\n",
    "**Key Statistical Analyses Performed:**\n",
    "- **Class Distribution**: Bar charts showing class counts per split with reduced font sizes\n",
    "- **Split Comparison**: Charts comparing train/val/test distributions\n",
    "- **Attribute Analysis**: Weather, scene, and time of day distributions\n",
    "- **Dataset Comparison**: Full vs Limited dataset with percentages shown alongside counts\n",
    "- **Coverage Analysis**: Comprehensive coverage verification across all dimensions\n",
    "- **Performance Metadata**: Per-image attributes ready for model evaluation\n",
    "\n",
    "**Annotation Strategy:**\n",
    "- **Per-Class Visualization**: Only the target class is annotated (clean, focused view)\n",
    "- **Multi-Object Scenes**: All classes are annotated (comprehensive scene understanding)\n",
    "\n",
    "**Performance Analysis Features:**\n",
    "- **Per-Image Attributes**: Weather, scene, timeofday for each image\n",
    "- **Class Distribution**: Objects per class for each image\n",
    "- **Evaluation Ready**: Data structured for attribute-based performance analysis in test notebook\n",
    "\n",
    "**Key Points:**\n",
    "- **Full Dataset**: ~100k images for comprehensive statistics and training\n",
    "- **Limited Dataset**: Representative samples ensuring comprehensive coverage\n",
    "- **Metadata Files**: Pre-computed statistics generated during dataset preparation\n",
    "- **Performance Data**: Per-image details for attribute-based model evaluation\n",
    "- **Integrity Checks**: Performed automatically during dataset preparation\n",
    "- **Font Sizes**: Reduced for better readability and professional appearance\n",
    "\n",
    "The dataset is now ready for YOLO model training with complete understanding of its composition and distribution!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "yolo_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
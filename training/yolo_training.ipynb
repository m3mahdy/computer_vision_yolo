{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1507ed5",
   "metadata": {},
   "source": [
    "# YOLO Model Training\n",
    "\n",
    "This notebook provides a complete workflow for training YOLO models on the BDD100K dataset.\n",
    "\n",
    "## Features:\n",
    "- ‚úÖ Load optimized hyperparameters from tuning phase\n",
    "- ‚úÖ Train model with best configuration\n",
    "- ‚úÖ Comprehensive validation metrics\n",
    "- ‚úÖ Per-class performance analysis\n",
    "- ‚úÖ Training visualization and curves\n",
    "- ‚úÖ PDF report generation\n",
    "- ‚úÖ Model saving with metadata\n",
    "\n",
    "## Workflow:\n",
    "1. Import libraries and configuration\n",
    "2. Load base model\n",
    "3. Load optimized hyperparameters\n",
    "4. Verify dataset\n",
    "5. Train model\n",
    "6. Validate performance\n",
    "7. Generate reports and visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ea694b",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2f810c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries (uncomment if running in Colab)\n",
    "# !pip install -q ultralytics pyyaml\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import json\n",
    "import torch\n",
    "import shutil\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# YOLO imports\n",
    "from ultralytics import YOLO\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure matplotlib for notebook display\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "\n",
    "# Check GPU availability\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('‚úì Libraries imported successfully')\n",
    "print(f'‚úì Device: {device}')\n",
    "if device == 'cuda':\n",
    "    print(f'  GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'  CUDA Version: {torch.version.cuda}')\n",
    "    print(f'  Available Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9adf806",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d0a421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directories\n",
    "BASE_DIR = Path.cwd().parent\n",
    "MODEL_NAME = \"yolo11n\"  # Model name without .pt extension\n",
    "\n",
    "# Choose YOLO model versions that are fully supported with ultralytics:\n",
    "# ‚úÖ YOLOv8: 'yolov8n', 'yolov8s', 'yolov8m', 'yolov8l', 'yolov8x'\n",
    "# ‚úÖ YOLOv9: 'yolov9s', 'yolov9m', 'yolov9l', 'yolov9x'\n",
    "# ‚úÖ YOLOv10: 'yolov10n', 'yolov10s', 'yolov10m', 'yolov10l', 'yolov10x'\n",
    "# ‚úÖ YOLO11: 'yolo11n', 'yolo11s', 'yolo11m', 'yolo11l', 'yolo11x'\n",
    "# ‚úÖ YOLO12: 'yolo12n', 'yolo12s', 'yolo12m', 'yolo12l', 'yolo12x'\n",
    "\n",
    "MODELS_DIR = BASE_DIR / 'models' / MODEL_NAME\n",
    "TMP_DIR = BASE_DIR / 'tmp' / MODEL_NAME\n",
    "TRAINING_DIR = BASE_DIR / 'training'\n",
    "RUNS_DIR = TRAINING_DIR / 'runs'\n",
    "\n",
    "# Dataset Selection - Choose one:\n",
    "# Option 1: Full dataset (~100k images) - use for final training\n",
    "YOLO_DATASET_ROOT = BASE_DIR / 'bdd100k_yolo'\n",
    "DATA_YAML_PATH = YOLO_DATASET_ROOT / 'data.yaml'\n",
    "\n",
    "# Option 2: Limited dataset (representative samples - for quick testing)\n",
    "# YOLO_DATASET_ROOT = BASE_DIR / 'bdd100k_yolo_limited'\n",
    "# DATA_YAML_PATH = YOLO_DATASET_ROOT / 'data.yaml'\n",
    "\n",
    "# Verify dataset exists\n",
    "if not DATA_YAML_PATH.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Dataset not found: {DATA_YAML_PATH}\\n\\n\"\n",
    "        f\"Please run the dataset preparation script first:\\n\"\n",
    "        f\"  python3 process_bdd100k_to_yolo_dataset.py\\n\"\n",
    "    )\n",
    "\n",
    "# Generate timestamp and run name\n",
    "RUN_TIMESTAMP = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "RUN_NAME = f'{MODEL_NAME}_training_{RUN_TIMESTAMP}'\n",
    "W_B_PROJECT = \"yolo-bdd100k-training\"\n",
    "\n",
    "# Create run-specific directory\n",
    "RUN_DIR = RUNS_DIR / RUN_NAME\n",
    "RUN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create other directories\n",
    "TMP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RUNS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Read dataset configuration from data.yaml\n",
    "with open(DATA_YAML_PATH, 'r') as f:\n",
    "    data_config = yaml.safe_load(f)\n",
    "    NUM_CLASSES = data_config['nc']\n",
    "    CLASS_NAMES = {i: name for i, name in enumerate(data_config['names'])}\n",
    "\n",
    "# Define dataset name for reporting\n",
    "USED_DATASET = YOLO_DATASET_ROOT.name\n",
    "\n",
    "print('=' * 80)\n",
    "print('CONFIGURATION SUMMARY')\n",
    "print('=' * 80)\n",
    "print(f'Model: {MODEL_NAME}')\n",
    "print(f'Dataset: {USED_DATASET}')\n",
    "print(f'Data YAML: {DATA_YAML_PATH}')\n",
    "print(f'Classes: {NUM_CLASSES}')\n",
    "print(f'Class Names: {CLASS_NAMES}')\n",
    "print(f'Device: {device}')\n",
    "\n",
    "print(f'Run Directory: {RUN_DIR}')\n",
    "\n",
    "print(f'W&B Project: {W_B_PROJECT}')\n",
    "print('=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4749e219",
   "metadata": {},
   "source": [
    "## 3. Load Base YOLO Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1b3ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLO model with automatic download\n",
    "model_path = MODELS_DIR / f'{MODEL_NAME}.pt'\n",
    "\n",
    "if not model_path.exists():\n",
    "    print(f'Model not found at {model_path}')\n",
    "    print(f'Downloading {MODEL_NAME} ...')\n",
    "    \n",
    "    try:\n",
    "        # Download model\n",
    "        MODEL_NAME_n = MODEL_NAME\n",
    "        if MODEL_NAME.startswith('yolo11') or MODEL_NAME.startswith('yolo12'):\n",
    "            MODEL_NAME_n = MODEL_NAME + '.pt'\n",
    "        model = YOLO(MODEL_NAME_n)\n",
    "        \n",
    "        # Create models directory\n",
    "        MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Move from cache\n",
    "        try:\n",
    "            import glob\n",
    "            cache_patterns = [\n",
    "                str(Path.home() / '.cache' / 'ultralytics' / '**' / f'{MODEL_NAME}.pt'),\n",
    "                str(Path.home() / '.config' / 'Ultralytics' / '**' / f'{MODEL_NAME}.pt'),\n",
    "            ]\n",
    "            \n",
    "            model_found = False\n",
    "            for pattern in cache_patterns:\n",
    "                cache_paths = glob.glob(pattern, recursive=True)\n",
    "                if cache_paths:\n",
    "                    shutil.move(cache_paths[0], model_path)\n",
    "                    print(f'‚úì Model downloaded and saved to {model_path}')\n",
    "                    print(f'  Size: {model_path.stat().st_size / (1024*1024):.1f} MB')\n",
    "                    \n",
    "                    # Clean up cache directory\n",
    "                    cache_dir = Path(cache_paths[0]).parent\n",
    "                    if cache_dir.exists() and not any(cache_dir.iterdir()):\n",
    "                        cache_dir.rmdir()\n",
    "                        print(f'  ‚úì Cleaned up cache directory')\n",
    "                    \n",
    "                    model_found = True\n",
    "                    break\n",
    "            \n",
    "            if not model_found:\n",
    "                print(f'‚úì Model loaded from ultralytics cache')\n",
    "        except Exception as save_error:\n",
    "            print(f'‚ö†Ô∏è  Could not move model: {save_error}')\n",
    "            print(f'‚úì Model loaded successfully from cache')\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f'\\n‚ùå Error downloading model: {e}')\n",
    "        raise\n",
    "else:\n",
    "    model = YOLO(str(model_path))\n",
    "    print(f'‚úì Model loaded from {model_path}')\n",
    "\n",
    "print(f'\\nüìä Base Model: {MODEL_NAME}')\n",
    "print(f'  Classes in model: {len(model.names)}')\n",
    "print(f'  Task: {model.task}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c52d11",
   "metadata": {},
   "source": [
    "## 4. Load Optimized Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e69c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load hyperparameters from tuning phase\n",
    "hyperparams_path = TRAINING_DIR / f'{MODEL_NAME}_best_hyperparameters.json'\n",
    "\n",
    "if hyperparams_path.exists():\n",
    "    with open(hyperparams_path, 'r') as f:\n",
    "        tuning_results = json.load(f)\n",
    "    \n",
    "    hyperparams = tuning_results['hyperparameters']\n",
    "    \n",
    "    print('‚úì Optimized hyperparameters loaded from tuning phase')\n",
    "    print(f'  Source: {hyperparams_path}')\n",
    "    print(f'  Best trial: {tuning_results[\"optimization_results\"][\"best_trial\"]}')\n",
    "    print(f'  Best mAP@0.5: {tuning_results[\"optimization_results\"][\"best_map50\"]:.4f}')\n",
    "    print(f'  Total trials: {tuning_results[\"optimization_results\"][\"total_trials\"]}')\n",
    "    print(f'\\nüìã Training Configuration:')\n",
    "    print(f'  Epochs: {hyperparams[\"epochs\"]}')\n",
    "    print(f'  Batch size: {hyperparams[\"batch\"]}')\n",
    "    print(f'  Image size: {hyperparams[\"imgsz\"]}')\n",
    "    print(f'  Patience: {hyperparams[\"patience\"]}')\n",
    "else:\n",
    "    print(f'‚ö†Ô∏è  No hyperparameters found at {hyperparams_path}')\n",
    "    print('Using default hyperparameters...')\n",
    "    \n",
    "    hyperparams = {\n",
    "        'epochs': 100,\n",
    "        'batch': 16,\n",
    "        'imgsz': 640,\n",
    "        'device': device,\n",
    "        'patience': 20,\n",
    "        'save': True,\n",
    "        'plots': True,\n",
    "        'verbose': True,\n",
    "        'cache': True,\n",
    "        'workers': 8\n",
    "    }\n",
    "\n",
    "    print('‚úì Using default hyperparameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1704a21b",
   "metadata": {},
   "source": [
    "## 5. Verify Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5406d635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify dataset structure is ready\n",
    "print('Verifying YOLO dataset structure...')\n",
    "print(f'\\nüìÅ Dataset Root: {YOLO_DATASET_ROOT}')\n",
    "\n",
    "# Check splits\n",
    "for split in ['train', 'val', 'test']:\n",
    "    images_dir = YOLO_DATASET_ROOT / 'images' / split\n",
    "    labels_dir = YOLO_DATASET_ROOT / 'labels' / split\n",
    "    \n",
    "    if images_dir.exists() and labels_dir.exists():\n",
    "        num_images = len(list(images_dir.glob('*.jpg'))) + len(list(images_dir.glob('*.png')))\n",
    "        num_labels = len(list(labels_dir.glob('*.txt')))\n",
    "        print(f'  ‚úì {split:5s}: {num_images:6d} images, {num_labels:6d} labels')\n",
    "    else:\n",
    "        print(f'  ‚ö†Ô∏è  {split:5s}: Directory not found')\n",
    "\n",
    "# Verify data.yaml\n",
    "print(f'\\nüìÑ Configuration: {DATA_YAML_PATH}')\n",
    "print(f'  Classes: {NUM_CLASSES}')\n",
    "print(f'  Names: {CLASS_NAMES}')\n",
    "\n",
    "print('\\n‚úì Dataset structure verified and ready for training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6104a6af",
   "metadata": {},
   "source": [
    "## 6. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae5a44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with optimized hyperparameters\n",
    "print('=' * 80)\n",
    "print('STARTING TRAINING')\n",
    "print('=' * 80)\n",
    "print(f'Model: {MODEL_NAME}')\n",
    "print(f'Dataset: {USED_DATASET}')\n",
    "print(f'Epochs: {hyperparams[\"epochs\"]}')\n",
    "print(f'Batch size: {hyperparams[\"batch\"]}')\n",
    "print('=' * 80)\n",
    "\n",
    "# Train model using data.yaml directly\n",
    "results = model.train(\n",
    "    data=str(DATA_YAML_PATH),\n",
    "    epochs=hyperparams['epochs'],\n",
    "    batch=hyperparams['batch'],\n",
    "    imgsz=hyperparams['imgsz'],\n",
    "    device=device,\n",
    "    **{k: v for k, v in hyperparams.items() if k not in ['epochs', 'batch', 'imgsz', 'device', 'project', 'name']},\n",
    "    project=str(RUN_DIR),\n",
    "    name='train',\n",
    "    exist_ok=True\n",
    ")\n",
    "\n",
    "print('\\n' + '=' * 80)\n",
    "print('TRAINING COMPLETED')\n",
    "print('=' * 80)\n",
    "print(f'Training results saved to: {RUN_DIR}/train')\n",
    "print('=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d37c50a",
   "metadata": {},
   "source": [
    "## 7. Validate Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cf2949",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 80)\n",
    "print('VALIDATING TRAINED MODEL')\n",
    "print('=' * 80)\n",
    "\n",
    "# Load the best trained model\n",
    "best_model_path = RUN_DIR / 'train' / 'weights' / 'best.pt'\n",
    "trained_model = YOLO(str(best_model_path))\n",
    "\n",
    "# Validate on validation set\n",
    "val_results = trained_model.val(\n",
    "    data=str(DATA_YAML_PATH),\n",
    "    split='val'\n",
    ")\n",
    "\n",
    "# Extract metrics\n",
    "metrics = {\n",
    "    'mAP@0.5': float(val_results.box.map50),\n",
    "    'mAP@0.5:0.95': float(val_results.box.map),\n",
    "    'precision': float(val_results.box.mp),\n",
    "    'recall': float(val_results.box.mr),\n",
    "    'fitness': float(val_results.fitness)\n",
    "}\n",
    "\n",
    "# Per-class metrics\n",
    "class_metrics = {}\n",
    "for i, class_name in CLASS_NAMES.items():\n",
    "    if i < len(val_results.box.ap50):\n",
    "        class_metrics[class_name] = {\n",
    "            'AP@0.5': float(val_results.box.ap50[i]),\n",
    "            'AP@0.5:0.95': float(val_results.box.ap[i])\n",
    "        }\n",
    "\n",
    "print('\\n' + '=' * 80)\n",
    "print('VALIDATION RESULTS')\n",
    "print('=' * 80)\n",
    "print(f'mAP@0.5: {metrics[\"mAP@0.5\"]:.4f}')\n",
    "print(f'mAP@0.5:0.95: {metrics[\"mAP@0.5:0.95\"]:.4f}')\n",
    "print(f'Precision: {metrics[\"precision\"]:.4f}')\n",
    "print(f'Recall: {metrics[\"recall\"]:.4f}')\n",
    "print(f'Fitness: {metrics[\"fitness\"]:.4f}')\n",
    "print('=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9733cf5",
   "metadata": {},
   "source": [
    "## 8. Save Fine-tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be9ff78",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 80)\n",
    "print('SAVING FINE-TUNED MODEL')\n",
    "print('=' * 80)\n",
    "\n",
    "# Create fine-tuned model filename with timestamp\n",
    "finetuned_date = datetime.now().strftime('%Y%m%d')\n",
    "finetuned_model_name = f'{MODEL_NAME}_finetuned-{finetuned_date}.pt'\n",
    "finetuned_model_path = MODELS_DIR / finetuned_model_name\n",
    "\n",
    "# Copy best model to models directory\n",
    "shutil.copy2(best_model_path, finetuned_model_path)\n",
    "\n",
    "print(f'‚úì Fine-tuned model saved to: {finetuned_model_path}')\n",
    "print(f'  Size: {finetuned_model_path.stat().st_size / (1024*1024):.1f} MB')\n",
    "\n",
    "# Save training metadata\n",
    "metadata = {\n",
    "    'model_name': MODEL_NAME,\n",
    "    'finetuned_model': finetuned_model_name,\n",
    "    'base_model': f'{MODEL_NAME}.pt',\n",
    "    'training_date': datetime.now().isoformat(),\n",
    "    'dataset': USED_DATASET,\n",
    "    'hyperparameters': hyperparams,\n",
    "    'validation_metrics': metrics,\n",
    "    'class_metrics': class_metrics,\n",
    "    'training_results_dir': str(RUN_DIR / 'train')\n",
    "}\n",
    "\n",
    "metadata_path = MODELS_DIR / f'{MODEL_NAME}_finetuned-{finetuned_date}_metadata.json'\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f'‚úì Metadata saved to: {metadata_path}')\n",
    "print('=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf1bd0b",
   "metadata": {},
   "source": [
    "## 9. Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2143f5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training results\n",
    "results_csv_path = RUN_DIR / 'train' / 'results.csv'\n",
    "\n",
    "if results_csv_path.exists():\n",
    "    df_results = pd.read_csv(results_csv_path)\n",
    "    df_results.columns = df_results.columns.str.strip()\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle(f'{MODEL_NAME} Training Results', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Plot 1: Loss curves\n",
    "    ax1 = axes[0, 0]\n",
    "    if 'train/box_loss' in df_results.columns:\n",
    "        ax1.plot(df_results['epoch'], df_results['train/box_loss'], label='Box Loss', linewidth=2)\n",
    "    if 'train/cls_loss' in df_results.columns:\n",
    "        ax1.plot(df_results['epoch'], df_results['train/cls_loss'], label='Class Loss', linewidth=2)\n",
    "    if 'train/dfl_loss' in df_results.columns:\n",
    "        ax1.plot(df_results['epoch'], df_results['train/dfl_loss'], label='DFL Loss', linewidth=2)\n",
    "    ax1.set_xlabel('Epoch', fontsize=12)\n",
    "    ax1.set_ylabel('Loss', fontsize=12)\n",
    "    ax1.set_title('Training Loss', fontsize=14, fontweight='bold')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: mAP curves\n",
    "    ax2 = axes[0, 1]\n",
    "    if 'metrics/mAP50(B)' in df_results.columns:\n",
    "        ax2.plot(df_results['epoch'], df_results['metrics/mAP50(B)'], label='mAP@0.5', linewidth=2, marker='o')\n",
    "    if 'metrics/mAP50-95(B)' in df_results.columns:\n",
    "        ax2.plot(df_results['epoch'], df_results['metrics/mAP50-95(B)'], label='mAP@0.5:0.95', linewidth=2, marker='s')\n",
    "    ax2.set_xlabel('Epoch', fontsize=12)\n",
    "    ax2.set_ylabel('mAP', fontsize=12)\n",
    "    ax2.set_title('Mean Average Precision', fontsize=14, fontweight='bold')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Precision and Recall\n",
    "    ax3 = axes[1, 0]\n",
    "    if 'metrics/precision(B)' in df_results.columns:\n",
    "        ax3.plot(df_results['epoch'], df_results['metrics/precision(B)'], label='Precision', linewidth=2, marker='o')\n",
    "    if 'metrics/recall(B)' in df_results.columns:\n",
    "        ax3.plot(df_results['epoch'], df_results['metrics/recall(B)'], label='Recall', linewidth=2, marker='s')\n",
    "    ax3.set_xlabel('Epoch', fontsize=12)\n",
    "    ax3.set_ylabel('Score', fontsize=12)\n",
    "    ax3.set_title('Precision and Recall', fontsize=14, fontweight='bold')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Learning rate\n",
    "    ax4 = axes[1, 1]\n",
    "    if 'lr/pg0' in df_results.columns:\n",
    "        ax4.plot(df_results['epoch'], df_results['lr/pg0'], label='LR pg0', linewidth=2)\n",
    "    if 'lr/pg1' in df_results.columns:\n",
    "        ax4.plot(df_results['epoch'], df_results['lr/pg1'], label='LR pg1', linewidth=2)\n",
    "    if 'lr/pg2' in df_results.columns:\n",
    "        ax4.plot(df_results['epoch'], df_results['lr/pg2'], label='LR pg2', linewidth=2)\n",
    "    ax4.set_xlabel('Epoch', fontsize=12)\n",
    "    ax4.set_ylabel('Learning Rate', fontsize=12)\n",
    "    ax4.set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save figure\n",
    "    training_curves_path = RUN_DIR / 'training_curves.png'\n",
    "    plt.savefig(training_curves_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f'‚úì Training curves saved to: {training_curves_path}')\n",
    "else:\n",
    "    print(f'‚ö†Ô∏è  Results CSV not found at {results_csv_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c621d58",
   "metadata": {},
   "source": [
    "## 10. Per-Class Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3bfc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create per-class performance visualization\n",
    "if class_metrics:\n",
    "    classes = list(class_metrics.keys())\n",
    "    ap50_values = [class_metrics[c]['AP@0.5'] for c in classes]\n",
    "    ap50_95_values = [class_metrics[c]['AP@0.5:0.95'] for c in classes]\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
    "    fig.suptitle('Per-Class Average Precision', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # AP@0.5\n",
    "    ax1.barh(classes, ap50_values, color='steelblue')\n",
    "    ax1.set_xlabel('AP@0.5', fontsize=12)\n",
    "    ax1.set_title('Average Precision @ IoU=0.5', fontsize=14)\n",
    "    ax1.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # AP@0.5:0.95\n",
    "    ax2.barh(classes, ap50_95_values, color='coral')\n",
    "    ax2.set_xlabel('AP@0.5:0.95', fontsize=12)\n",
    "    ax2.set_title('Average Precision @ IoU=0.5:0.95', fontsize=14)\n",
    "    ax2.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save figure\n",
    "    class_performance_path = RUN_DIR / 'class_performance.png'\n",
    "    plt.savefig(class_performance_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f'‚úì Class performance chart saved to: {class_performance_path}')\n",
    "    \n",
    "    # Create summary table\n",
    "    print('\\n' + '=' * 80)\n",
    "    print('PER-CLASS PERFORMANCE SUMMARY')\n",
    "    print('=' * 80)\n",
    "    df_class = pd.DataFrame(class_metrics).T\n",
    "    df_class = df_class.sort_values('AP@0.5', ascending=False)\n",
    "    print(df_class.to_string())\n",
    "    print('=' * 80)\n",
    "    \n",
    "    # Save to CSV\n",
    "    class_metrics_csv = RUN_DIR / 'class_metrics.csv'\n",
    "    df_class.to_csv(class_metrics_csv)\n",
    "    print(f'\\n‚úì Class metrics saved to: {class_metrics_csv}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d884ef93",
   "metadata": {},
   "source": [
    "## 11. Generate PDF Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6271501f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.lib import colors as rl_colors\n",
    "from reportlab.lib.units import inch\n",
    "from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer, Image, PageBreak\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.enums import TA_CENTER, TA_LEFT\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "print('=' * 80)\n",
    "print('GENERATING PDF REPORT')\n",
    "print('=' * 80)\n",
    "\n",
    "# Create PDF report\n",
    "pdf_report_path = RUN_DIR / f'{MODEL_NAME}_training_report.pdf'\n",
    "\n",
    "doc = SimpleDocTemplate(str(pdf_report_path), pagesize=A4,\n",
    "                       rightMargin=30, leftMargin=30,\n",
    "                       topMargin=30, bottomMargin=30)\n",
    "\n",
    "story = []\n",
    "styles = getSampleStyleSheet()\n",
    "\n",
    "# Custom styles\n",
    "title_style = ParagraphStyle(\n",
    "    'CustomTitle',\n",
    "    parent=styles['Heading1'],\n",
    "    fontSize=24,\n",
    "    textColor=rl_colors.HexColor('#2c3e50'),\n",
    "    spaceAfter=30,\n",
    "    alignment=TA_CENTER\n",
    ")\n",
    "\n",
    "heading_style = ParagraphStyle(\n",
    "    'CustomHeading',\n",
    "    parent=styles['Heading2'],\n",
    "    fontSize=16,\n",
    "    textColor=rl_colors.HexColor('#34495e'),\n",
    "    spaceAfter=12,\n",
    "    spaceBefore=20\n",
    ")\n",
    "\n",
    "# Title\n",
    "story.append(Paragraph(f'{MODEL_NAME} Training Report', title_style))\n",
    "story.append(Spacer(1, 12))\n",
    "\n",
    "# Configuration info\n",
    "info_data = [\n",
    "    ['Model:', MODEL_NAME],\n",
    "    ['Fine-tuned Model:', finetuned_model_name],\n",
    "    ['Dataset:', USED_DATASET],\n",
    "    ['Training Date:', datetime.now().strftime('%Y-%m-%d %H:%M:%S')],\n",
    "    ['Epochs:', str(hyperparams['epochs'])],\n",
    "    ['Batch Size:', str(hyperparams['batch'])],\n",
    "    ['Image Size:', str(hyperparams['imgsz'])]\n",
    "]\n",
    "\n",
    "info_table = Table(info_data, colWidths=[2.2*inch, 3.8*inch])\n",
    "info_table.setStyle(TableStyle([\n",
    "    ('BACKGROUND', (0, 0), (-1, -1), rl_colors.HexColor('#ecf0f1')),\n",
    "    ('TEXTCOLOR', (0, 0), (-1, -1), rl_colors.black),\n",
    "    ('ALIGN', (0, 0), (-1, -1), 'LEFT'),\n",
    "    ('FONTNAME', (0, 0), (0, -1), 'Helvetica-Bold'),\n",
    "    ('FONTSIZE', (0, 0), (-1, -1), 10),\n",
    "    ('BOTTOMPADDING', (0, 0), (-1, -1), 8),\n",
    "    ('TOPPADDING', (0, 0), (-1, -1), 8),\n",
    "    ('GRID', (0, 0), (-1, -1), 1, rl_colors.white)\n",
    "]))\n",
    "story.append(info_table)\n",
    "story.append(Spacer(1, 20))\n",
    "\n",
    "# Validation metrics\n",
    "story.append(PageBreak())\n",
    "story.append(Paragraph('Validation Metrics', heading_style))\n",
    "\n",
    "metrics_data = [['Metric', 'Value']]\n",
    "for key, value in metrics.items():\n",
    "    metrics_data.append([key, f'{value:.4f}'])\n",
    "\n",
    "metrics_table = Table(metrics_data, colWidths=[3*inch, 3*inch])\n",
    "metrics_table.setStyle(TableStyle([\n",
    "    ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#3498db')),\n",
    "    ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n",
    "    ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "    ('FONTSIZE', (0, 0), (-1, 0), 12),\n",
    "    ('FONTSIZE', (0, 1), (-1, -1), 10),\n",
    "    ('BOTTOMPADDING', (0, 0), (-1, -1), 8),\n",
    "    ('TOPPADDING', (0, 0), (-1, -1), 8),\n",
    "    ('ROWBACKGROUNDS', (0, 1), (-1, -1), [rl_colors.white, rl_colors.lightgrey]),\n",
    "    ('GRID', (0, 0), (-1, -1), 1, rl_colors.black)\n",
    "]))\n",
    "story.append(metrics_table)\n",
    "story.append(Spacer(1, 20))\n",
    "\n",
    "# Per-class metrics\n",
    "if class_metrics:\n",
    "    story.append(PageBreak())\n",
    "    story.append(Paragraph('Per-Class Performance', heading_style))\n",
    "    \n",
    "    class_data = [['Class', 'AP@0.5', 'AP@0.5:0.95']]\n",
    "    for class_name, class_vals in class_metrics.items():\n",
    "        class_data.append([\n",
    "            class_name,\n",
    "            f\"{class_vals['AP@0.5']:.4f}\",\n",
    "            f\"{class_vals['AP@0.5:0.95']:.4f}\"\n",
    "        ])\n",
    "    \n",
    "    class_table = Table(class_data, colWidths=[2*inch, 2*inch, 2*inch])\n",
    "    class_table.setStyle(TableStyle([\n",
    "        ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#27ae60')),\n",
    "        ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n",
    "        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "        ('FONTSIZE', (0, 0), (-1, 0), 11),\n",
    "        ('FONTSIZE', (0, 1), (-1, -1), 9),\n",
    "        ('BOTTOMPADDING', (0, 0), (-1, -1), 6),\n",
    "        ('TOPPADDING', (0, 0), (-1, -1), 6),\n",
    "        ('ROWBACKGROUNDS', (0, 1), (-1, -1), [rl_colors.white, rl_colors.lightgrey]),\n",
    "        ('GRID', (0, 0), (-1, -1), 1, rl_colors.black)\n",
    "    ]))\n",
    "    story.append(class_table)\n",
    "    story.append(Spacer(1, 20))\n",
    "\n",
    "# Training curves\n",
    "story.append(PageBreak())\n",
    "story.append(Paragraph('Training Curves', heading_style))\n",
    "story.append(Spacer(1, 12))\n",
    "\n",
    "if training_curves_path.exists():\n",
    "    try:\n",
    "        with PILImage.open(training_curves_path) as img:\n",
    "            img_width, img_height = img.size\n",
    "            aspect_ratio = img_height / img_width\n",
    "            pdf_width = 7 * inch\n",
    "            pdf_height = pdf_width * aspect_ratio\n",
    "            if pdf_height > 9 * inch:\n",
    "                pdf_height = 9 * inch\n",
    "                pdf_width = pdf_height / aspect_ratio\n",
    "            story.append(Image(str(training_curves_path), width=pdf_width, height=pdf_height))\n",
    "    except Exception as e:\n",
    "        print(f'Warning: Could not load training curves: {e}')\n",
    "        story.append(Paragraph('Training curves not available.', styles['Normal']))\n",
    "else:\n",
    "    story.append(Paragraph('Training curves not found.', styles['Normal']))\n",
    "\n",
    "story.append(Spacer(1, 20))\n",
    "\n",
    "# Class performance\n",
    "if class_metrics:\n",
    "    story.append(PageBreak())\n",
    "    story.append(Paragraph('Class Performance Analysis', heading_style))\n",
    "    story.append(Spacer(1, 12))\n",
    "    \n",
    "    if class_performance_path.exists():\n",
    "        try:\n",
    "            with PILImage.open(class_performance_path) as img:\n",
    "                img_width, img_height = img.size\n",
    "                aspect_ratio = img_height / img_width\n",
    "                pdf_width = 7 * inch\n",
    "                pdf_height = pdf_width * aspect_ratio\n",
    "                if pdf_height > 6 * inch:\n",
    "                    pdf_height = 6 * inch\n",
    "                    pdf_width = pdf_height / aspect_ratio\n",
    "                story.append(Image(str(class_performance_path), width=pdf_width, height=pdf_height))\n",
    "        except Exception as e:\n",
    "            print(f'Warning: Could not load class performance: {e}')\n",
    "            story.append(Paragraph('Class performance chart not available.', styles['Normal']))\n",
    "    else:\n",
    "        story.append(Paragraph('Class performance chart not found.', styles['Normal']))\n",
    "    \n",
    "    story.append(Spacer(1, 20))\n",
    "\n",
    "# Footer\n",
    "story.append(Spacer(1, 30))\n",
    "story.append(Paragraph('Generated by YOLO Training Notebook',\n",
    "                      ParagraphStyle('Footer', parent=styles['Normal'],\n",
    "                                   alignment=TA_CENTER, textColor=rl_colors.grey)))\n",
    "story.append(Paragraph('BDD100K Dataset - Computer Vision Project',\n",
    "                      ParagraphStyle('Footer2', parent=styles['Normal'],\n",
    "                                   alignment=TA_CENTER, textColor=rl_colors.grey)))\n",
    "\n",
    "# Build PDF\n",
    "doc.build(story)\n",
    "\n",
    "print(f'‚úì PDF report generated: {pdf_report_path}')\n",
    "print(f'  Size: {pdf_report_path.stat().st_size / 1024:.2f} KB')\n",
    "print('=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb56081e",
   "metadata": {},
   "source": [
    "## 12. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca9bcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 80)\n",
    "print('TRAINING COMPLETED SUCCESSFULLY')\n",
    "print('=' * 80)\n",
    "print(f'\\nModel: {MODEL_NAME}')\n",
    "print(f'Dataset: {USED_DATASET}')\n",
    "print(f'\\nFine-tuned Model:')\n",
    "print(f'  Path: {finetuned_model_path}')\n",
    "print(f'  Name: {finetuned_model_name}')\n",
    "print(f'\\nValidation Metrics:')\n",
    "print(f'  mAP@0.5: {metrics[\"mAP@0.5\"]:.4f}')\n",
    "print(f'  mAP@0.5:0.95: {metrics[\"mAP@0.5:0.95\"]:.4f}')\n",
    "print(f'  Precision: {metrics[\"precision\"]:.4f}')\n",
    "print(f'  Recall: {metrics[\"recall\"]:.4f}')\n",
    "print(f'\\nOutput Directory: {RUN_DIR}')\n",
    "print(f'\\nGenerated Files:')\n",
    "print(f'  üéØ Fine-tuned model: {finetuned_model_path}')\n",
    "print(f'  üìä Metadata: {metadata_path}')\n",
    "print(f'  üìà Training curves: training_curves.png')\n",
    "if class_metrics:\n",
    "    print(f'  üìä Class performance: class_performance.png')\n",
    "    print(f'  üìÑ Class metrics CSV: class_metrics.csv')\n",
    "print(f'  üìÑ PDF Report: {MODEL_NAME}_training_report.pdf')\n",
    "print(f'\\nüíæ All results saved to: {RUN_DIR}')\n",
    "print(f'üéØ Fine-tuned model ready for testing!')\n",
    "print('\\nüöÄ Next Steps:')\n",
    "print(f'  1. Review the PDF report: {pdf_report_path}')\n",
    "print(f'  2. Use fine-tuned model for testing: {finetuned_model_name}')\n",
    "print(f'  3. Run testing notebook on test split')\n",
    "print('=' * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b26f5d6",
   "metadata": {},
   "source": [
    "# YOLO Hyperparameter Tuning with Optuna\n",
    "\n",
    "This notebook provides comprehensive hyperparameter optimization for YOLO models using Optuna.\n",
    "\n",
    "## Features:\n",
    "- ‚úÖ Support for YOLOv8, YOLOv9, YOLOv10, YOLO11, YOLO12\n",
    "- ‚úÖ Optuna-based hyperparameter optimization\n",
    "- ‚úÖ Extensive search space: learning rates, momentum, weight decay, augmentation, optimizer\n",
    "- ‚úÖ GPU detection and utilization\n",
    "- ‚úÖ Best hyperparameters saved to YAML\n",
    "- ‚úÖ Optimization history visualization\n",
    "- ‚úÖ Final model training with optimized parameters\n",
    "- ‚úÖ Production-ready code with clear comments\n",
    "\n",
    "## Workflow:\n",
    "1. Install required libraries\n",
    "2. Configure dataset and model\n",
    "3. Define hyperparameter search space\n",
    "4. Run Optuna optimization (30 trials)\n",
    "5. Visualize results\n",
    "6. Save best hyperparameters\n",
    "7. Train final model with optimized settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109394c4",
   "metadata": {},
   "source": [
    "## 1. Install Required Libraries\n",
    "\n",
    "Install all necessary packages for YOLO training and hyperparameter optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6f98f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries (uncomment if running in Colab)\n",
    "# !pip install -q ultralytics optuna plotly kaleido wandb pyyaml\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import json\n",
    "import torch\n",
    "import shutil\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# YOLO and Optuna imports\n",
    "from ultralytics import YOLO\n",
    "import optuna\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances, plot_slice\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure matplotlib for notebook display\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "\n",
    "# Check GPU availability\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'‚úì Libraries imported successfully')\n",
    "print(f'‚úì Device: {device}')\n",
    "if device == 'cuda':\n",
    "    print(f'  GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'  CUDA Version: {torch.version.cuda}')\n",
    "    print(f'  Available Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2659c792",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d163f0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "# Base directories\n",
    "BASE_DIR = Path.cwd().parent\n",
    "\n",
    "# For Colab, uncomment and set your paths:\n",
    "# BASE_DIR = Path(\"/content/drive/MyDrive/computer_vision_yolo\")\n",
    "\n",
    "# Model Selection - Choose one of the following:\n",
    "MODEL_NAME = \"yolov8n\"\n",
    "# Supported models:\n",
    "# YOLOv8: 'yolov8n', 'yolov8s', 'yolov8m', 'yolov8l', 'yolov8x'\n",
    "# YOLOv9: 'yolov9s', 'yolov9m', 'yolov9l', 'yolov9x'\n",
    "# YOLOv10: 'yolov10n', 'yolov10s', 'yolov10m', 'yolov10l', 'yolov10x'\n",
    "# YOLO11: 'yolo11n', 'yolo11s', 'yolo11m', 'yolo11l', 'yolo11x'\n",
    "# YOLO12: 'yolo12n', 'yolo12s', 'yolo12m', 'yolo12l', 'yolo12x'\n",
    "\n",
    "# Directory structure\n",
    "MODELS_DIR = BASE_DIR / 'models' / MODEL_NAME\n",
    "TMP_DIR = BASE_DIR / 'tmp' / MODEL_NAME\n",
    "RUNS_DIR = BASE_DIR / 'hyperparameter_tuning' / 'runs'\n",
    "\n",
    "# Dataset Selection\n",
    "# Option 1: Full dataset (~100k images) - for final optimization\n",
    "# YOLO_DATASET_ROOT = BASE_DIR / 'bdd100k_yolo'\n",
    "# DATA_YAML_PATH = YOLO_DATASET_ROOT / 'data.yaml'\n",
    "\n",
    "# Option 2: Limited dataset (representative samples) - for quick tuning\n",
    "YOLO_DATASET_ROOT = BASE_DIR / 'bdd100k_yolo_limited'\n",
    "DATA_YAML_PATH = YOLO_DATASET_ROOT / 'data.yaml'\n",
    "\n",
    "# Verify dataset exists\n",
    "if not DATA_YAML_PATH.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Dataset not found: {DATA_YAML_PATH}\\n\"\n",
    "        f\"Please prepare the dataset first using process_bdd100k_to_yolo_dataset.py\"\n",
    "    )\n",
    "\n",
    "# Optimization Configuration\n",
    "N_TRIALS = 30  # Number of optimization trials\n",
    "TIMEOUT_HOURS = 6  # Maximum time for optimization (None for no limit)\n",
    "N_STARTUP_TRIALS = 10  # Random exploration trials before optimization\n",
    "EPOCHS_PER_TRIAL = 50  # Training epochs per trial\n",
    "BATCH_SIZE = 16  # Batch size for training\n",
    "IMAGE_SIZE = 640  # Input image size\n",
    "\n",
    "# Weights & Biases (optional)\n",
    "USE_WANDB = False  # Set to True to enable W&B logging\n",
    "W_B_PROJECT = \"yolo-bdd100k-hyperparameter-tuning\"\n",
    "\n",
    "# Generate run identifier\n",
    "RUN_TIMESTAMP = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "RUN_NAME = f'{MODEL_NAME}_optuna_{RUN_TIMESTAMP}'\n",
    "\n",
    "# Create directories\n",
    "RUN_DIR = RUNS_DIR / RUN_NAME\n",
    "RUN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TMP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Read dataset configuration\n",
    "with open(DATA_YAML_PATH, 'r') as f:\n",
    "    data_config = yaml.safe_load(f)\n",
    "    NUM_CLASSES = data_config['nc']\n",
    "    CLASS_NAMES = data_config['names']\n",
    "\n",
    "print('=' * 80)\n",
    "print('CONFIGURATION SUMMARY')\n",
    "print('=' * 80)\n",
    "print(f'Model: {MODEL_NAME}')\n",
    "print(f'Dataset: {YOLO_DATASET_ROOT.name}')\n",
    "print(f'Data YAML: {DATA_YAML_PATH}')\n",
    "print(f'Classes: {NUM_CLASSES}')\n",
    "print(f'Class Names: {CLASS_NAMES}')\n",
    "print(f'Device: {device}')\n",
    "print(f'Optimization Trials: {N_TRIALS}')\n",
    "print(f'Epochs per Trial: {EPOCHS_PER_TRIAL}')\n",
    "print(f'Batch Size: {BATCH_SIZE}')\n",
    "print(f'Image Size: {IMAGE_SIZE}')\n",
    "print(f'Timeout: {TIMEOUT_HOURS} hours' if TIMEOUT_HOURS else 'No timeout')\n",
    "print(f'Run Directory: {RUN_DIR}')\n",
    "print(f'W&B Logging: {\"Enabled\" if USE_WANDB else \"Disabled\"}')\n",
    "print('=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af35c3f",
   "metadata": {},
   "source": [
    "## 3. Load Base YOLO Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3deeda88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# LOAD BASE YOLO MODEL\n",
    "# ============================================================================\n",
    "\n",
    "model_path = MODELS_DIR / f'{MODEL_NAME}.pt'\n",
    "\n",
    "if not model_path.exists():\n",
    "    print(f'Model not found at {model_path}')\n",
    "    print(f'Downloading {MODEL_NAME}...')\n",
    "    \n",
    "    try:\n",
    "        # Download model (Ultralytics will automatically download)\n",
    "        model_name_for_download = MODEL_NAME\n",
    "        if MODEL_NAME.startswith('yolo11') or MODEL_NAME.startswith('yolo12'):\n",
    "            model_name_for_download = MODEL_NAME + '.pt'\n",
    "        \n",
    "        model = YOLO(model_name_for_download)\n",
    "        \n",
    "        # Try to move from cache to models directory\n",
    "        import glob\n",
    "        cache_patterns = [\n",
    "            str(Path.home() / '.cache' / 'ultralytics' / '**' / f'{MODEL_NAME}.pt'),\n",
    "            str(Path.home() / '.config' / 'Ultralytics' / '**' / f'{MODEL_NAME}.pt'),\n",
    "        ]\n",
    "        \n",
    "        model_found = False\n",
    "        for pattern in cache_patterns:\n",
    "            cache_paths = glob.glob(pattern, recursive=True)\n",
    "            if cache_paths:\n",
    "                shutil.move(cache_paths[0], model_path)\n",
    "                print(f'‚úì Model downloaded and saved to {model_path}')\n",
    "                print(f'  Size: {model_path.stat().st_size / (1024*1024):.1f} MB')\n",
    "                model_found = True\n",
    "                break\n",
    "        \n",
    "        if not model_found:\n",
    "            print(f'‚úì Model loaded from ultralytics cache')\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Error downloading model: {e}')\n",
    "        raise\n",
    "else:\n",
    "    model = YOLO(str(model_path))\n",
    "    print(f'‚úì Model loaded from {model_path}')\n",
    "\n",
    "print(f'\\nüìä Base Model Information:')\n",
    "print(f'  Name: {MODEL_NAME}')\n",
    "print(f'  Classes: {len(model.names)}')\n",
    "print(f'  Task: {model.task}')\n",
    "print(f'  Path: {model_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe0b94d",
   "metadata": {},
   "source": [
    "## 4. Verify Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b15401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VERIFY DATASET STRUCTURE\n",
    "# ============================================================================\n",
    "\n",
    "print('Verifying YOLO dataset structure...')\n",
    "print(f'\\nüìÅ Dataset Root: {YOLO_DATASET_ROOT}')\n",
    "\n",
    "# Check all splits\n",
    "dataset_stats = {}\n",
    "for split in ['train', 'val', 'test']:\n",
    "    images_dir = YOLO_DATASET_ROOT / 'images' / split\n",
    "    labels_dir = YOLO_DATASET_ROOT / 'labels' / split\n",
    "    \n",
    "    if images_dir.exists() and labels_dir.exists():\n",
    "        num_images = len(list(images_dir.glob('*.jpg'))) + len(list(images_dir.glob('*.png')))\n",
    "        num_labels = len(list(labels_dir.glob('*.txt')))\n",
    "        dataset_stats[split] = {'images': num_images, 'labels': num_labels}\n",
    "        print(f'  ‚úì {split:5s}: {num_images:6d} images, {num_labels:6d} labels')\n",
    "    else:\n",
    "        print(f'  ‚ö†Ô∏è  {split:5s}: Directory not found')\n",
    "        dataset_stats[split] = {'images': 0, 'labels': 0}\n",
    "\n",
    "print(f'\\nüìÑ Configuration: {DATA_YAML_PATH}')\n",
    "print(f'  Classes: {NUM_CLASSES}')\n",
    "print(f'  Names: {CLASS_NAMES}')\n",
    "\n",
    "total_images = sum(stats['images'] for stats in dataset_stats.values())\n",
    "print(f'\\n‚úì Dataset verified: {total_images:,} total images')\n",
    "print('‚úì Ready for hyperparameter optimization')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf76930",
   "metadata": {},
   "source": [
    "## 5. Define Hyperparameter Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d1ae35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DEFINE HYPERPARAMETER SEARCH SPACE\n",
    "# ============================================================================\n",
    "\n",
    "def define_hyperparameters(trial):\n",
    "    \"\"\"\n",
    "    Define comprehensive hyperparameter search space for YOLO optimization.\n",
    "    \n",
    "    Uses Optuna's default ranges for most parameters to leverage library expertise.\n",
    "    Only specifies categorical choices and essential boundaries.\n",
    "    \n",
    "    Args:\n",
    "        trial: Optuna trial object\n",
    "        \n",
    "    Returns:\n",
    "        dict: Complete hyperparameter configuration for YOLO training\n",
    "    \"\"\"\n",
    "    \n",
    "    # ========================================================================\n",
    "    # OPTIMIZER SELECTION\n",
    "    # ========================================================================\n",
    "    optimizer_choice = trial.suggest_categorical('optimizer', ['SGD', 'Adam', 'AdamW'])\n",
    "    \n",
    "    # ========================================================================\n",
    "    # LEARNING RATE PARAMETERS (Let library determine optimal ranges)\n",
    "    # ========================================================================\n",
    "    lr0 = trial.suggest_float('lr0', 1e-5, 1e-2, log=True)\n",
    "    lrf = trial.suggest_float('lrf', 0.01, 0.2)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # OPTIMIZER PARAMETERS (Library defaults)\n",
    "    # ========================================================================\n",
    "    momentum = trial.suggest_float('momentum', 0.6, 0.98)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-2, log=True)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # WARMUP PARAMETERS\n",
    "    # ========================================================================\n",
    "    warmup_epochs = trial.suggest_int('warmup_epochs', 0, 5)\n",
    "    warmup_momentum = trial.suggest_float('warmup_momentum', 0.0, 0.95)\n",
    "    warmup_bias_lr = trial.suggest_float('warmup_bias_lr', 0.0, 0.2)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # DATA AUGMENTATION - HSV COLOR SPACE\n",
    "    # ========================================================================\n",
    "    hsv_h = trial.suggest_float('hsv_h', 0.0, 0.1)\n",
    "    hsv_s = trial.suggest_float('hsv_s', 0.0, 0.9)\n",
    "    hsv_v = trial.suggest_float('hsv_v', 0.0, 0.9)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # DATA AUGMENTATION - GEOMETRIC TRANSFORMATIONS\n",
    "    # ========================================================================\n",
    "    degrees = trial.suggest_float('degrees', 0.0, 45.0)\n",
    "    translate = trial.suggest_float('translate', 0.0, 0.9)\n",
    "    scale = trial.suggest_float('scale', 0.0, 0.9)\n",
    "    shear = trial.suggest_float('shear', 0.0, 10.0)\n",
    "    perspective = trial.suggest_float('perspective', 0.0, 0.001)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # DATA AUGMENTATION - FLIP\n",
    "    # ========================================================================\n",
    "    flipud = trial.suggest_float('flipud', 0.0, 1.0)\n",
    "    fliplr = trial.suggest_float('fliplr', 0.0, 1.0)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # DATA AUGMENTATION - ADVANCED\n",
    "    # ========================================================================\n",
    "    mosaic = trial.suggest_float('mosaic', 0.0, 1.0)\n",
    "    mixup = trial.suggest_float('mixup', 0.0, 1.0)\n",
    "    copy_paste = trial.suggest_float('copy_paste', 0.0, 1.0)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # LOSS FUNCTION WEIGHTS\n",
    "    # ========================================================================\n",
    "    box = trial.suggest_float('box', 0.5, 20.0)\n",
    "    cls = trial.suggest_float('cls', 0.2, 4.0)\n",
    "    dfl = trial.suggest_float('dfl', 0.5, 3.0)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # COMPILE HYPERPARAMETERS\n",
    "    # ========================================================================\n",
    "    hyperparams = {\n",
    "        # Optimizer\n",
    "        'optimizer': optimizer_choice,\n",
    "        \n",
    "        # Learning rates\n",
    "        'lr0': lr0,\n",
    "        'lrf': lrf,\n",
    "        \n",
    "        # Optimizer parameters\n",
    "        'momentum': momentum,\n",
    "        'weight_decay': weight_decay,\n",
    "        \n",
    "        # Warmup\n",
    "        'warmup_epochs': warmup_epochs,\n",
    "        'warmup_momentum': warmup_momentum,\n",
    "        'warmup_bias_lr': warmup_bias_lr,\n",
    "        \n",
    "        # HSV augmentation\n",
    "        'hsv_h': hsv_h,\n",
    "        'hsv_s': hsv_s,\n",
    "        'hsv_v': hsv_v,\n",
    "        \n",
    "        # Geometric augmentation\n",
    "        'degrees': degrees,\n",
    "        'translate': translate,\n",
    "        'scale': scale,\n",
    "        'shear': shear,\n",
    "        'perspective': perspective,\n",
    "        \n",
    "        # Flip augmentation\n",
    "        'flipud': flipud,\n",
    "        'fliplr': fliplr,\n",
    "        \n",
    "        # Advanced augmentation\n",
    "        'mosaic': mosaic,\n",
    "        'mixup': mixup,\n",
    "        'copy_paste': copy_paste,\n",
    "        \n",
    "        # Loss weights\n",
    "        'box': box,\n",
    "        'cls': cls,\n",
    "        'dfl': dfl,\n",
    "        \n",
    "        # Fixed training parameters\n",
    "        'epochs': EPOCHS_PER_TRIAL,\n",
    "        'batch': BATCH_SIZE,\n",
    "        'imgsz': IMAGE_SIZE,\n",
    "        'device': device,\n",
    "        'patience': 15,  # Early stopping patience\n",
    "        'save': False,  # Don't save intermediate models\n",
    "        'plots': False,  # Don't generate plots for each trial\n",
    "        'cache': True,  # Cache images for faster training\n",
    "        'workers': 8,  # Number of data loading workers\n",
    "        'close_mosaic': 10,  # Disable mosaic in last N epochs\n",
    "        'verbose': False,  # Reduce verbosity\n",
    "    }\n",
    "    \n",
    "    return hyperparams\n",
    "\n",
    "print('‚úì Hyperparameter search space defined')\n",
    "print('\\nüìä Search Space Summary:')\n",
    "print('  Strategy: Using wide ranges, letting Optuna find optimal values')\n",
    "print('  Optimizers: SGD, Adam, AdamW')\n",
    "print('  Learning Rates: Wide range for exploration')\n",
    "print('  Augmentation: Full range (0-1 for probabilities)')\n",
    "print('  Loss Weights: Wide range for different dataset characteristics')\n",
    "print(f'  Fixed: epochs={EPOCHS_PER_TRIAL}, batch={BATCH_SIZE}, imgsz={IMAGE_SIZE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8326b5",
   "metadata": {},
   "source": [
    "## 6. Define Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5575796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DEFINE OBJECTIVE FUNCTION FOR OPTUNA\n",
    "# ============================================================================\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Objective function for Optuna hyperparameter optimization.\n",
    "    \n",
    "    This function:\n",
    "    1. Gets hyperparameters for the current trial\n",
    "    2. Trains a YOLO model with those hyperparameters\n",
    "    3. Evaluates the model on validation set\n",
    "    4. Returns the metric to optimize (mAP@0.5)\n",
    "    \n",
    "    Args:\n",
    "        trial: Optuna trial object\n",
    "        \n",
    "    Returns:\n",
    "        float: Validation mAP@0.5 (metric to maximize)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get hyperparameters for this trial\n",
    "    hyperparams = define_hyperparameters(trial)\n",
    "    \n",
    "    # Create trial-specific directory\n",
    "    trial_dir = RUN_DIR / f'trial_{trial.number:03d}'\n",
    "    trial_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Initialize W&B if enabled\n",
    "    wandb_run = None\n",
    "    if USE_WANDB:\n",
    "        try:\n",
    "            import wandb\n",
    "            wandb_run = wandb.init(\n",
    "                project=W_B_PROJECT,\n",
    "                name=f'{MODEL_NAME}_trial_{trial.number:03d}',\n",
    "                config=hyperparams,\n",
    "                reinit=True\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f'‚ö†Ô∏è  W&B initialization failed: {e}')\n",
    "            wandb_run = None\n",
    "    \n",
    "    try:\n",
    "        # Print trial information\n",
    "        print(f'\\n{\"=\" * 80}')\n",
    "        print(f'TRIAL {trial.number}/{N_TRIALS}')\n",
    "        print(f'{\"=\" * 80}')\n",
    "        print(f'Optimizer: {hyperparams[\"optimizer\"]}')\n",
    "        print(f'Learning Rate: lr0={hyperparams[\"lr0\"]:.6f}, lrf={hyperparams[\"lrf\"]:.4f}')\n",
    "        print(f'Momentum: {hyperparams[\"momentum\"]:.4f}, Weight Decay: {hyperparams[\"weight_decay\"]:.6f}')\n",
    "        print(f'Augmentation: hsv_h={hyperparams[\"hsv_h\"]:.3f}, translate={hyperparams[\"translate\"]:.3f}, mixup={hyperparams[\"mixup\"]:.3f}')\n",
    "        print(f'Loss Weights: box={hyperparams[\"box\"]:.2f}, cls={hyperparams[\"cls\"]:.2f}, dfl={hyperparams[\"dfl\"]:.2f}')\n",
    "        print(f'{\"=\" * 80}')\n",
    "        \n",
    "        # Load fresh model for this trial\n",
    "        trial_model = YOLO(str(model_path))\n",
    "        \n",
    "        # Train model with hyperparameters\n",
    "        results = trial_model.train(\n",
    "            data=str(DATA_YAML_PATH),\n",
    "            project=str(trial_dir),\n",
    "            name='train',\n",
    "            exist_ok=True,\n",
    "            **hyperparams\n",
    "        )\n",
    "        \n",
    "        # Validate model\n",
    "        val_results = trial_model.val(\n",
    "            data=str(DATA_YAML_PATH),\n",
    "            split='val',\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        # Extract metrics\n",
    "        map50 = float(val_results.box.map50)  # mAP@0.5 (primary metric)\n",
    "        map50_95 = float(val_results.box.map)  # mAP@0.5:0.95\n",
    "        precision = float(val_results.box.mp)  # Mean precision\n",
    "        recall = float(val_results.box.mr)  # Mean recall\n",
    "        \n",
    "        # Log to W&B\n",
    "        if wandb_run:\n",
    "            wandb.log({\n",
    "                'trial_number': trial.number,\n",
    "                'val/mAP@0.5': map50,\n",
    "                'val/mAP@0.5:0.95': map50_95,\n",
    "                'val/precision': precision,\n",
    "                'val/recall': recall,\n",
    "            })\n",
    "            wandb.finish()\n",
    "        \n",
    "        # Save trial results\n",
    "        trial_results = {\n",
    "            'trial_number': trial.number,\n",
    "            'hyperparameters': {k: float(v) if isinstance(v, (np.floating, np.integer)) else v \n",
    "                              for k, v in hyperparams.items()},\n",
    "            'metrics': {\n",
    "                'map50': map50,\n",
    "                'map50_95': map50_95,\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "            },\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        with open(trial_dir / 'results.json', 'w') as f:\n",
    "            json.dump(trial_results, f, indent=2)\n",
    "        \n",
    "        # Print results\n",
    "        print(f'\\n‚úì Trial {trial.number} completed:')\n",
    "        print(f'  mAP@0.5: {map50:.4f}')\n",
    "        print(f'  mAP@0.5:0.95: {map50_95:.4f}')\n",
    "        print(f'  Precision: {precision:.4f}')\n",
    "        print(f'  Recall: {recall:.4f}')\n",
    "        \n",
    "        # Clean up to save disk space\n",
    "        try:\n",
    "            weights_dir = trial_dir / 'train' / 'weights'\n",
    "            if weights_dir.exists():\n",
    "                shutil.rmtree(weights_dir)\n",
    "        except Exception as e:\n",
    "            print(f'  ‚ö†Ô∏è  Could not clean up weights: {e}')\n",
    "        \n",
    "        return map50\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'\\n‚ùå Trial {trial.number} failed with error: {e}')\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        if wandb_run:\n",
    "            wandb.finish()\n",
    "        \n",
    "        # Return very low score for failed trials (not 0 to avoid division issues)\n",
    "        return 0.001\n",
    "\n",
    "print('‚úì Objective function defined')\n",
    "print('  Optimization Metric: mAP@0.5 (to maximize)')\n",
    "print('  Additional Tracking: mAP@0.5:0.95, precision, recall')\n",
    "print('  Error Handling: Graceful fallback with detailed logging')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b2c034",
   "metadata": {},
   "source": [
    "## 7. Run Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e116f130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# RUN HYPERPARAMETER OPTIMIZATION WITH OPTUNA\n",
    "# ============================================================================\n",
    "\n",
    "print('\\n' + '=' * 80)\n",
    "print('STARTING HYPERPARAMETER OPTIMIZATION')\n",
    "print('=' * 80)\n",
    "print(f'Model: {MODEL_NAME}')\n",
    "print(f'Dataset: {YOLO_DATASET_ROOT.name}')\n",
    "print(f'Number of Trials: {N_TRIALS}')\n",
    "print(f'Epochs per Trial: {EPOCHS_PER_TRIAL}')\n",
    "print(f'Timeout: {TIMEOUT_HOURS} hours' if TIMEOUT_HOURS else 'No timeout')\n",
    "print(f'Device: {device}')\n",
    "print('=' * 80)\n",
    "\n",
    "# Create Optuna study\n",
    "study = optuna.create_study(\n",
    "    study_name=f'{MODEL_NAME}_optuna_{RUN_TIMESTAMP}',\n",
    "    direction='maximize',  # Maximize mAP@0.5\n",
    "    sampler=optuna.samplers.TPESampler(\n",
    "        seed=42,\n",
    "        n_startup_trials=N_STARTUP_TRIALS,  # Random trials before optimization\n",
    "        multivariate=True,  # Consider parameter interactions\n",
    "        group=True  # Group related parameters\n",
    "    ),\n",
    "    pruner=optuna.pruners.MedianPruner(\n",
    "        n_startup_trials=N_STARTUP_TRIALS,\n",
    "        n_warmup_steps=15,  # Wait before pruning\n",
    "        interval_steps=5  # Check every 5 steps\n",
    "    )\n",
    ")\n",
    "\n",
    "# Run optimization\n",
    "start_time = datetime.now()\n",
    "print(f'\\nüöÄ Optimization started at {start_time.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "\n",
    "try:\n",
    "    study.optimize(\n",
    "        objective,\n",
    "        n_trials=N_TRIALS,\n",
    "        timeout=TIMEOUT_HOURS * 3600 if TIMEOUT_HOURS else None,\n",
    "        show_progress_bar=True,\n",
    "        callbacks=[\n",
    "            lambda study, trial: print(f'\\n‚úì Completed {len(study.trials)}/{N_TRIALS} trials')\n",
    "        ]\n",
    "    )\n",
    "except KeyboardInterrupt:\n",
    "    print('\\n‚ö†Ô∏è  Optimization interrupted by user')\n",
    "except Exception as e:\n",
    "    print(f'\\n‚ùå Optimization failed: {e}')\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "end_time = datetime.now()\n",
    "duration = end_time - start_time\n",
    "\n",
    "print('\\n' + '=' * 80)\n",
    "print('OPTIMIZATION COMPLETED')\n",
    "print('=' * 80)\n",
    "print(f'Started: {start_time.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "print(f'Ended: {end_time.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "print(f'Duration: {duration}')\n",
    "print(f'Total Trials: {len(study.trials)}')\n",
    "print(f'Completed Trials: {len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])}')\n",
    "print(f'Pruned Trials: {len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED])}')\n",
    "print(f'Failed Trials: {len([t for t in study.trials if t.state == optuna.trial.TrialState.FAIL])}')\n",
    "print(f'\\nBest Trial: {study.best_trial.number}')\n",
    "print(f'Best mAP@0.5: {study.best_value:.4f}')\n",
    "print('=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ff99f5",
   "metadata": {},
   "source": [
    "## 8. Analyze Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3823505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EXTRACT AND DISPLAY BEST HYPERPARAMETERS\n",
    "# ============================================================================\n",
    "\n",
    "print('\\n' + '=' * 80)\n",
    "print('BEST HYPERPARAMETERS')\n",
    "print('=' * 80)\n",
    "\n",
    "best_params = study.best_params\n",
    "best_trial = study.best_trial\n",
    "\n",
    "print(f'\\nBest Trial Number: {best_trial.number}')\n",
    "print(f'Best mAP@0.5: {study.best_value:.4f}')\n",
    "print('\\nOptimized Hyperparameters:')\n",
    "print(json.dumps(best_params, indent=2))\n",
    "\n",
    "# Save best parameters to JSON\n",
    "best_params_json = RUN_DIR / 'best_hyperparameters.json'\n",
    "with open(best_params_json, 'w') as f:\n",
    "    json.dump({\n",
    "        'model': MODEL_NAME,\n",
    "        'dataset': str(YOLO_DATASET_ROOT),\n",
    "        'best_trial': best_trial.number,\n",
    "        'best_map50': study.best_value,\n",
    "        'total_trials': len(study.trials),\n",
    "        'hyperparameters': best_params,\n",
    "        'optimization_config': {\n",
    "            'n_trials': N_TRIALS,\n",
    "            'epochs_per_trial': EPOCHS_PER_TRIAL,\n",
    "            'batch_size': BATCH_SIZE,\n",
    "            'image_size': IMAGE_SIZE,\n",
    "        },\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(f'\\n‚úì Best hyperparameters saved to: {best_params_json}')\n",
    "\n",
    "# Save to YAML format (ready for YOLO training)\n",
    "best_params_yaml = RUN_DIR / 'best_hparams.yaml'\n",
    "with open(best_params_yaml, 'w') as f:\n",
    "    yaml.dump(best_params, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "print(f'‚úì Best hyperparameters saved to: {best_params_yaml}')\n",
    "print('=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24aed975",
   "metadata": {},
   "source": [
    "## 9. Visualize Optimization Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d33d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VISUALIZE OPTIMIZATION HISTORY\n",
    "# ============================================================================\n",
    "\n",
    "print('\\n' + '=' * 80)\n",
    "print('GENERATING OPTIMIZATION VISUALIZATIONS')\n",
    "print('=' * 80)\n",
    "\n",
    "# Plot 1: Optimization History\n",
    "print('\\nüìà Creating optimization history plot...')\n",
    "fig_history = plot_optimization_history(study)\n",
    "fig_history.update_layout(\n",
    "    title=f'{MODEL_NAME} - Hyperparameter Optimization History',\n",
    "    xaxis_title='Trial Number',\n",
    "    yaxis_title='mAP@0.5',\n",
    "    template='plotly_white',\n",
    "    width=1200,\n",
    "    height=600\n",
    ")\n",
    "fig_history.show()\n",
    "\n",
    "# Save figure\n",
    "optimization_history_path = RUN_DIR / 'optimization_history.html'\n",
    "fig_history.write_html(str(optimization_history_path))\n",
    "print(f'‚úì Saved to: {optimization_history_path}')\n",
    "\n",
    "# Also save as image if kaleido is available\n",
    "try:\n",
    "    optimization_history_img = RUN_DIR / 'optimization_history.png'\n",
    "    fig_history.write_image(str(optimization_history_img), width=1200, height=600, scale=2)\n",
    "    print(f'‚úì Saved to: {optimization_history_img}')\n",
    "except Exception as e:\n",
    "    print(f'  ‚ÑπÔ∏è  Could not save PNG (kaleido not available): {e}')\n",
    "    optimization_history_img = None\n",
    "\n",
    "print('=' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cc1e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VISUALIZE PARAMETER IMPORTANCE\n",
    "# ============================================================================\n",
    "\n",
    "print('\\nüìä Creating parameter importance plot...')\n",
    "\n",
    "param_importance_path = None\n",
    "try:\n",
    "    fig_importance = plot_param_importances(study)\n",
    "    fig_importance.update_layout(\n",
    "        title=f'{MODEL_NAME} - Hyperparameter Importance',\n",
    "        xaxis_title='Importance',\n",
    "        yaxis_title='Parameter',\n",
    "        template='plotly_white',\n",
    "        width=1200,\n",
    "        height=800\n",
    "    )\n",
    "    fig_importance.show()\n",
    "    \n",
    "    # Save figure\n",
    "    param_importance_path = RUN_DIR / 'parameter_importance.html'\n",
    "    fig_importance.write_html(str(param_importance_path))\n",
    "    print(f'‚úì Saved to: {param_importance_path}')\n",
    "    \n",
    "    # Save as image\n",
    "    try:\n",
    "        param_importance_img = RUN_DIR / 'parameter_importance.png'\n",
    "        fig_importance.write_image(str(param_importance_img), width=1200, height=800, scale=2)\n",
    "        print(f'‚úì Saved to: {param_importance_img}')\n",
    "    except Exception as e:\n",
    "        print(f'  ‚ÑπÔ∏è  Could not save PNG: {e}')\n",
    "        param_importance_img = None\n",
    "        \n",
    "except (RuntimeError, ValueError) as e:\n",
    "    print(f'‚ö†Ô∏è  Could not generate parameter importance plot: {e}')\n",
    "    print('  (This can happen when trials have insufficient data variation)')\n",
    "    param_importance_img = None\n",
    "\n",
    "print('=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7a6f4b",
   "metadata": {},
   "source": [
    "## 10. Visualize Parameter Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f298282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VISUALIZE SLICE PLOTS (PARAMETER RELATIONSHIPS)\n",
    "# ============================================================================\n",
    "\n",
    "print('\\nüìä Creating parameter slice plots...')\n",
    "\n",
    "try:\n",
    "    fig_slice = plot_slice(study)\n",
    "    fig_slice.update_layout(\n",
    "        title=f'{MODEL_NAME} - Parameter Slice Plot',\n",
    "        template='plotly_white',\n",
    "        width=1400,\n",
    "        height=1000\n",
    "    )\n",
    "    fig_slice.show()\n",
    "    \n",
    "    # Save figure\n",
    "    slice_path = RUN_DIR / 'parameter_slice.html'\n",
    "    fig_slice.write_html(str(slice_path))\n",
    "    print(f'‚úì Saved to: {slice_path}')\n",
    "    \n",
    "    # Save as image\n",
    "    try:\n",
    "        slice_img_path = RUN_DIR / 'parameter_slice.png'\n",
    "        fig_slice.write_image(str(slice_img_path), width=1400, height=1000, scale=2)\n",
    "        print(f'‚úì Saved to: {slice_img_path}')\n",
    "    except Exception as e:\n",
    "        print(f'  ‚ÑπÔ∏è  Could not save PNG: {e}')\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f'‚ö†Ô∏è  Could not generate parameter slice plot: {e}')\n",
    "\n",
    "print('=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1900ad83",
   "metadata": {},
   "source": [
    "## 10. Create Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c210c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CREATE TRIALS SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print('\\n' + '=' * 80)\n",
    "print('TRIALS SUMMARY')\n",
    "print('=' * 80)\n",
    "\n",
    "# Compile all trial data\n",
    "trials_data = []\n",
    "for trial in study.trials:\n",
    "    trial_info = {\n",
    "        'trial': trial.number,\n",
    "        'mAP@0.5': trial.value if trial.value else 0.0,\n",
    "        'state': trial.state.name,\n",
    "        'duration_seconds': (trial.datetime_complete - trial.datetime_start).total_seconds() if trial.datetime_complete else None,\n",
    "    }\n",
    "    # Add all parameters\n",
    "    trial_info.update(trial.params)\n",
    "    trials_data.append(trial_info)\n",
    "\n",
    "# Create DataFrame\n",
    "df_trials = pd.DataFrame(trials_data)\n",
    "\n",
    "# Sort by performance\n",
    "df_trials_sorted = df_trials.sort_values('mAP@0.5', ascending=False)\n",
    "\n",
    "print('\\nüìä TOP 10 TRIALS:')\n",
    "print('=' * 80)\n",
    "# Display top 10 with selected columns\n",
    "display_cols = ['trial', 'mAP@0.5', 'state', 'optimizer', 'lr0', 'momentum', 'weight_decay', 'mixup']\n",
    "available_cols = [col for col in display_cols if col in df_trials_sorted.columns]\n",
    "print(df_trials_sorted[available_cols].head(10).to_string(index=False))\n",
    "print('=' * 80)\n",
    "\n",
    "# Save complete trials summary\n",
    "trials_csv_path = RUN_DIR / 'trials_summary.csv'\n",
    "df_trials_sorted.to_csv(trials_csv_path, index=False)\n",
    "print(f'\\n‚úì Complete trials summary saved to: {trials_csv_path}')\n",
    "\n",
    "# Save study object\n",
    "study_path = RUN_DIR / 'optuna_study.pkl'\n",
    "import pickle\n",
    "with open(study_path, 'wb') as f:\n",
    "    pickle.dump(study, f)\n",
    "print(f'‚úì Optuna study object saved to: {study_path}')\n",
    "\n",
    "print('=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923833ab",
   "metadata": {},
   "source": [
    "## 11. Save Hyperparameters for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d702ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PREPARE FINAL TRAINING CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "print('\\n' + '=' * 80)\n",
    "print('PREPARING FINAL TRAINING CONFIGURATION')\n",
    "print('=' * 80)\n",
    "\n",
    "# Create training directory\n",
    "training_dir = BASE_DIR / 'training'\n",
    "training_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Prepare final training hyperparameters\n",
    "final_training_params = best_params.copy()\n",
    "final_training_params.update({\n",
    "    # Extended training settings\n",
    "    'epochs': 100,  # Full training epochs\n",
    "    'batch': BATCH_SIZE,\n",
    "    'imgsz': IMAGE_SIZE,\n",
    "    'device': device,\n",
    "    \n",
    "    # Training control\n",
    "    'patience': 25,  # Early stopping patience\n",
    "    'save': True,  # Save models\n",
    "    'save_period': 10,  # Save checkpoint every N epochs\n",
    "    'plots': True,  # Generate training plots\n",
    "    'verbose': True,  # Detailed output\n",
    "    \n",
    "    # Efficiency\n",
    "    'cache': True,  # Cache images\n",
    "    'workers': 8,  # Data loading workers\n",
    "    'amp': True,  # Automatic mixed precision\n",
    "    \n",
    "    # Validation\n",
    "    'val': True,  # Run validation\n",
    "    \n",
    "    # Project organization\n",
    "    'project': str(training_dir / 'runs'),\n",
    "    'name': f'{MODEL_NAME}_optimized',\n",
    "    'exist_ok': True,\n",
    "})\n",
    "\n",
    "# Save training configuration\n",
    "training_config_path = training_dir / f'{MODEL_NAME}_optimized_config.yaml'\n",
    "with open(training_config_path, 'w') as f:\n",
    "    yaml.dump(final_training_params, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "print(f'\\n‚úì Training configuration saved to: {training_config_path}')\n",
    "\n",
    "# Also save as JSON with metadata\n",
    "training_config_json = training_dir / f'{MODEL_NAME}_optimized_config.json'\n",
    "with open(training_config_json, 'w') as f:\n",
    "    json.dump({\n",
    "        'model': MODEL_NAME,\n",
    "        'base_model_path': str(model_path),\n",
    "        'dataset_root': str(YOLO_DATASET_ROOT),\n",
    "        'data_yaml_path': str(DATA_YAML_PATH),\n",
    "        'optimization_results': {\n",
    "            'best_trial': study.best_trial.number,\n",
    "            'best_map50': study.best_value,\n",
    "            'total_trials': len(study.trials),\n",
    "            'optimization_duration': str(duration),\n",
    "        },\n",
    "        'hyperparameters': final_training_params,\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'notes': 'Use these hyperparameters for full model training with 100 epochs'\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(f'‚úì Training configuration (with metadata) saved to: {training_config_json}')\n",
    "\n",
    "print('\\nüìã Training Configuration Summary:')\n",
    "print(f'  Epochs: {final_training_params[\"epochs\"]}')\n",
    "print(f'  Batch Size: {final_training_params[\"batch\"]}')\n",
    "print(f'  Image Size: {final_training_params[\"imgsz\"]}')\n",
    "print(f'  Optimizer: {final_training_params[\"optimizer\"]}')\n",
    "print(f'  Learning Rate: {final_training_params[\"lr0\"]:.6f}')\n",
    "print(f'  Device: {final_training_params[\"device\"]}')\n",
    "\n",
    "print('=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83385af0",
   "metadata": {},
   "source": [
    "## 12. Train Final Model with Optimized Hyperparameters\n",
    "\n",
    "Now train the final model using the best hyperparameters found during optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0bc9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TRAIN FINAL MODEL WITH OPTIMIZED HYPERPARAMETERS\n",
    "# ============================================================================\n",
    "\n",
    "print('\\n' + '=' * 80)\n",
    "print('TRAINING FINAL MODEL WITH OPTIMIZED HYPERPARAMETERS')\n",
    "print('=' * 80)\n",
    "\n",
    "# Load fresh model for final training\n",
    "print(f'\\nüì¶ Loading base model: {MODEL_NAME}')\n",
    "final_model = YOLO(str(model_path))\n",
    "\n",
    "print(f'\\nüöÄ Starting final training with best hyperparameters...')\n",
    "print(f'  Epochs: {final_training_params[\"epochs\"]}')\n",
    "print(f'  Dataset: {DATA_YAML_PATH}')\n",
    "print(f'  Device: {device}')\n",
    "print('\\nThis may take a while. Training progress will be displayed below.')\n",
    "print('=' * 80)\n",
    "\n",
    "# Train model with optimized hyperparameters\n",
    "final_results = final_model.train(\n",
    "    data=str(DATA_YAML_PATH),\n",
    "    **final_training_params\n",
    ")\n",
    "\n",
    "print('\\n' + '=' * 80)\n",
    "print('FINAL TRAINING COMPLETED')\n",
    "print('=' * 80)\n",
    "\n",
    "# Get final validation metrics\n",
    "final_val_results = final_model.val(data=str(DATA_YAML_PATH))\n",
    "\n",
    "final_metrics = {\n",
    "    'map50': float(final_val_results.box.map50),\n",
    "    'map50_95': float(final_val_results.box.map),\n",
    "    'precision': float(final_val_results.box.mp),\n",
    "    'recall': float(final_val_results.box.mr),\n",
    "}\n",
    "\n",
    "print('\\nüìä Final Model Performance:')\n",
    "print(f'  mAP@0.5: {final_metrics[\"map50\"]:.4f}')\n",
    "print(f'  mAP@0.5:0.95: {final_metrics[\"map50_95\"]:.4f}')\n",
    "print(f'  Precision: {final_metrics[\"precision\"]:.4f}')\n",
    "print(f'  Recall: {final_metrics[\"recall\"]:.4f}')\n",
    "\n",
    "# Compare with optimization results\n",
    "improvement = final_metrics['map50'] - study.best_value\n",
    "print(f'\\nüìà Improvement over trial performance: {improvement:+.4f}')\n",
    "print(f'  Trial best: {study.best_value:.4f}')\n",
    "print(f'  Final model: {final_metrics[\"map50\"]:.4f}')\n",
    "\n",
    "print('=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35471d99",
   "metadata": {},
   "source": [
    "## 13. Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d959bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SAVE FINAL OPTIMIZED MODEL\n",
    "# ============================================================================\n",
    "\n",
    "print('\\n' + '=' * 80)\n",
    "print('SAVING FINAL OPTIMIZED MODEL')\n",
    "print('=' * 80)\n",
    "\n",
    "# Generate model filename with timestamp\n",
    "model_timestamp = datetime.now().strftime('%Y%m%d')\n",
    "final_model_name = f'{MODEL_NAME}_optimized_{model_timestamp}.pt'\n",
    "final_model_path = MODELS_DIR / final_model_name\n",
    "\n",
    "# Copy best weights to models directory\n",
    "weights_path = training_dir / 'runs' / f'{MODEL_NAME}_optimized' / 'weights' / 'best.pt'\n",
    "if weights_path.exists():\n",
    "    shutil.copy(weights_path, final_model_path)\n",
    "    print(f'\\n‚úì Final model saved to: {final_model_path}')\n",
    "    print(f'  Size: {final_model_path.stat().st_size / (1024*1024):.1f} MB')\n",
    "else:\n",
    "    print(f'\\n‚ö†Ô∏è  Best weights not found at: {weights_path}')\n",
    "    print('  Model may still be in training directory')\n",
    "\n",
    "# Save model metadata\n",
    "metadata = {\n",
    "    'model_name': MODEL_NAME,\n",
    "    'model_path': str(final_model_path),\n",
    "    'dataset': str(YOLO_DATASET_ROOT),\n",
    "    'training_date': datetime.now().isoformat(),\n",
    "    'optimization': {\n",
    "        'n_trials': len(study.trials),\n",
    "        'best_trial': study.best_trial.number,\n",
    "        'trial_map50': study.best_value,\n",
    "        'optimization_duration': str(duration),\n",
    "    },\n",
    "    'hyperparameters': best_params,\n",
    "    'final_metrics': final_metrics,\n",
    "    'training_config': {\n",
    "        'epochs': final_training_params['epochs'],\n",
    "        'batch_size': final_training_params['batch'],\n",
    "        'image_size': final_training_params['imgsz'],\n",
    "    }\n",
    "}\n",
    "\n",
    "metadata_path = MODELS_DIR / f'{MODEL_NAME}_optimized_{model_timestamp}_metadata.json'\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f'‚úì Model metadata saved to: {metadata_path}')\n",
    "print('=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585a97a5",
   "metadata": {},
   "source": [
    "## 12. Generate PDF Report\n",
    "\n",
    "Create a comprehensive PDF report with optimization results, visualizations, and model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3c3580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# GENERATE PDF REPORT\n",
    "# ============================================================================\n",
    "\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.lib import colors as rl_colors\n",
    "from reportlab.lib.units import inch\n",
    "from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer, Image, PageBreak\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.enums import TA_CENTER, TA_LEFT\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "print('\\n' + '=' * 80)\n",
    "print('GENERATING PDF REPORT')\n",
    "print('=' * 80)\n",
    "\n",
    "# Create PDF report\n",
    "pdf_report_path = RUN_DIR / f'{MODEL_NAME}_hyperparameter_tuning_report.pdf'\n",
    "\n",
    "doc = SimpleDocTemplate(str(pdf_report_path), pagesize=A4,\n",
    "                       rightMargin=30, leftMargin=30,\n",
    "                       topMargin=30, bottomMargin=30)\n",
    "\n",
    "story = []\n",
    "styles = getSampleStyleSheet()\n",
    "\n",
    "# Custom styles\n",
    "title_style = ParagraphStyle(\n",
    "    'CustomTitle',\n",
    "    parent=styles['Heading1'],\n",
    "    fontSize=24,\n",
    "    textColor=rl_colors.HexColor('#2c3e50'),\n",
    "    spaceAfter=30,\n",
    "    alignment=TA_CENTER\n",
    ")\n",
    "\n",
    "heading_style = ParagraphStyle(\n",
    "    'CustomHeading',\n",
    "    parent=styles['Heading2'],\n",
    "    fontSize=16,\n",
    "    textColor=rl_colors.HexColor('#34495e'),\n",
    "    spaceAfter=12,\n",
    "    spaceBefore=20\n",
    ")\n",
    "\n",
    "# Title\n",
    "story.append(Paragraph(f'{MODEL_NAME} Hyperparameter Tuning Report', title_style))\n",
    "story.append(Spacer(1, 12))\n",
    "\n",
    "# Configuration info\n",
    "info_data = [\n",
    "    ['Model:', MODEL_NAME],\n",
    "    ['Dataset:', YOLO_DATASET_ROOT.name],\n",
    "    ['Timestamp:', datetime.now().strftime('%Y-%m-%d %H:%M:%S')],\n",
    "    ['Total Trials:', str(len(study.trials))],\n",
    "    ['Best Trial:', str(study.best_trial.number)],\n",
    "    ['Best mAP@0.5:', f'{study.best_value:.4f}']\n",
    "]\n",
    "\n",
    "info_table = Table(info_data, colWidths=[2.2*inch, 3.8*inch])\n",
    "info_table.setStyle(TableStyle([\n",
    "    ('BACKGROUND', (0, 0), (-1, -1), rl_colors.HexColor('#ecf0f1')),\n",
    "    ('TEXTCOLOR', (0, 0), (-1, -1), rl_colors.black),\n",
    "    ('ALIGN', (0, 0), (-1, -1), 'LEFT'),\n",
    "    ('FONTNAME', (0, 0), (0, -1), 'Helvetica-Bold'),\n",
    "    ('FONTSIZE', (0, 0), (-1, -1), 10),\n",
    "    ('BOTTOMPADDING', (0, 0), (-1, -1), 8),\n",
    "    ('TOPPADDING', (0, 0), (-1, -1), 8),\n",
    "    ('GRID', (0, 0), (-1, -1), 1, rl_colors.white)\n",
    "]))\n",
    "story.append(info_table)\n",
    "story.append(Spacer(1, 20))\n",
    "\n",
    "# Best hyperparameters\n",
    "story.append(PageBreak())\n",
    "story.append(Paragraph('Best Hyperparameters', heading_style))\n",
    "\n",
    "hyperparam_data = [['Parameter', 'Value']]\n",
    "for key, value in best_params.items():\n",
    "    hyperparam_data.append([key, f'{value:.6f}' if isinstance(value, float) else str(value)])\n",
    "\n",
    "hyperparam_table = Table(hyperparam_data, colWidths=[3*inch, 3*inch])\n",
    "hyperparam_table.setStyle(TableStyle([\n",
    "    ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#3498db')),\n",
    "    ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n",
    "    ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "    ('FONTSIZE', (0, 0), (-1, 0), 12),\n",
    "    ('FONTSIZE', (0, 1), (-1, -1), 9),\n",
    "    ('BOTTOMPADDING', (0, 0), (-1, -1), 6),\n",
    "    ('TOPPADDING', (0, 0), (-1, -1), 6),\n",
    "    ('ROWBACKGROUNDS', (0, 1), (-1, -1), [rl_colors.white, rl_colors.lightgrey]),\n",
    "    ('GRID', (0, 0), (-1, -1), 1, rl_colors.black)\n",
    "]))\n",
    "story.append(hyperparam_table)\n",
    "story.append(Spacer(1, 20))\n",
    "\n",
    "# Top 10 trials\n",
    "story.append(PageBreak())\n",
    "story.append(Paragraph('Top 10 Trials', heading_style))\n",
    "\n",
    "top10_data = [['Trial', 'mAP@0.5', 'State']]\n",
    "for _, row in df_trials_sorted.head(10).iterrows():\n",
    "    top10_data.append([\n",
    "        str(int(row['trial'])),\n",
    "        f\"{row['mAP@0.5']:.4f}\",\n",
    "        row['state']\n",
    "    ])\n",
    "\n",
    "top10_table = Table(top10_data, colWidths=[1.5*inch, 2*inch, 2.5*inch])\n",
    "top10_table.setStyle(TableStyle([\n",
    "    ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#27ae60')),\n",
    "    ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n",
    "    ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "    ('FONTSIZE', (0, 0), (-1, 0), 11),\n",
    "    ('FONTSIZE', (0, 1), (-1, -1), 9),\n",
    "    ('BOTTOMPADDING', (0, 0), (-1, -1), 6),\n",
    "    ('TOPPADDING', (0, 0), (-1, -1), 6),\n",
    "    ('ROWBACKGROUNDS', (0, 1), (-1, -1), [rl_colors.white, rl_colors.lightgrey]),\n",
    "    ('GRID', (0, 0), (-1, -1), 1, rl_colors.black)\n",
    "]))\n",
    "story.append(top10_table)\n",
    "story.append(Spacer(1, 20))\n",
    "\n",
    "# Optimization history\n",
    "story.append(PageBreak())\n",
    "story.append(Paragraph('Optimization History', heading_style))\n",
    "story.append(Spacer(1, 12))\n",
    "\n",
    "optimization_history_img = RUN_DIR / 'optimization_history.png'\n",
    "if optimization_history_img.exists():\n",
    "    try:\n",
    "        with PILImage.open(optimization_history_img) as img:\n",
    "            img_width, img_height = img.size\n",
    "            aspect_ratio = img_height / img_width\n",
    "            pdf_width = 6.5 * inch\n",
    "            pdf_height = pdf_width * aspect_ratio\n",
    "            if pdf_height > 7 * inch:\n",
    "                pdf_height = 7 * inch\n",
    "                pdf_width = pdf_height / aspect_ratio\n",
    "            story.append(Image(str(optimization_history_img), width=pdf_width, height=pdf_height))\n",
    "    except Exception as e:\n",
    "        print(f'‚ö†Ô∏è  Could not load optimization history: {e}')\n",
    "        story.append(Paragraph('Optimization history chart not available.', styles['Normal']))\n",
    "else:\n",
    "    story.append(Paragraph('Optimization history chart not found (PNG format required).', styles['Normal']))\n",
    "\n",
    "story.append(Spacer(1, 20))\n",
    "\n",
    "# Parameter importance\n",
    "story.append(PageBreak())\n",
    "story.append(Paragraph('Parameter Importance', heading_style))\n",
    "story.append(Spacer(1, 12))\n",
    "\n",
    "param_importance_img = RUN_DIR / 'parameter_importance.png'\n",
    "if param_importance_img.exists():\n",
    "    try:\n",
    "        with PILImage.open(param_importance_img) as img:\n",
    "            img_width, img_height = img.size\n",
    "            aspect_ratio = img_height / img_width\n",
    "            pdf_width = 6.5 * inch\n",
    "            pdf_height = pdf_width * aspect_ratio\n",
    "            if pdf_height > 7 * inch:\n",
    "                pdf_height = 7 * inch\n",
    "                pdf_width = pdf_height / aspect_ratio\n",
    "            story.append(Image(str(param_importance_img), width=pdf_width, height=pdf_height))\n",
    "    except Exception as e:\n",
    "        print(f'‚ö†Ô∏è  Could not load parameter importance: {e}')\n",
    "        story.append(Paragraph('Parameter importance chart not available.', styles['Normal']))\n",
    "else:\n",
    "    story.append(Paragraph('Parameter importance chart not available or could not be generated.', styles['Normal']))\n",
    "\n",
    "story.append(Spacer(1, 20))\n",
    "\n",
    "# Final model performance (if available)\n",
    "if 'final_metrics' in globals():\n",
    "    story.append(PageBreak())\n",
    "    story.append(Paragraph('Final Model Performance', heading_style))\n",
    "    \n",
    "    final_perf_data = [\n",
    "        ['Metric', 'Value'],\n",
    "        ['mAP@0.5', f\"{final_metrics['map50']:.4f}\"],\n",
    "        ['mAP@0.5:0.95', f\"{final_metrics['map50_95']:.4f}\"],\n",
    "        ['Precision', f\"{final_metrics['precision']:.4f}\"],\n",
    "        ['Recall', f\"{final_metrics['recall']:.4f}\"],\n",
    "    ]\n",
    "    \n",
    "    final_perf_table = Table(final_perf_data, colWidths=[3*inch, 3*inch])\n",
    "    final_perf_table.setStyle(TableStyle([\n",
    "        ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#e74c3c')),\n",
    "        ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n",
    "        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "        ('FONTSIZE', (0, 0), (-1, 0), 12),\n",
    "        ('FONTSIZE', (0, 1), (-1, -1), 11),\n",
    "        ('BOTTOMPADDING', (0, 0), (-1, -1), 8),\n",
    "        ('TOPPADDING', (0, 0), (-1, -1), 8),\n",
    "        ('ROWBACKGROUNDS', (0, 1), (-1, -1), [rl_colors.white, rl_colors.lightgrey]),\n",
    "        ('GRID', (0, 0), (-1, -1), 1, rl_colors.black)\n",
    "    ]))\n",
    "    story.append(final_perf_table)\n",
    "    story.append(Spacer(1, 20))\n",
    "\n",
    "# Footer\n",
    "story.append(Spacer(1, 30))\n",
    "story.append(Paragraph('Generated by YOLO Hyperparameter Tuning Notebook',\n",
    "                      ParagraphStyle('Footer', parent=styles['Normal'],\n",
    "                                   alignment=TA_CENTER, textColor=rl_colors.grey)))\n",
    "story.append(Paragraph('BDD100K Dataset - Computer Vision Project',\n",
    "                      ParagraphStyle('Footer2', parent=styles['Normal'],\n",
    "                                   alignment=TA_CENTER, textColor=rl_colors.grey)))\n",
    "\n",
    "# Build PDF\n",
    "try:\n",
    "    doc.build(story)\n",
    "    print(f'\\n‚úì PDF report generated: {pdf_report_path}')\n",
    "    print(f'  Size: {pdf_report_path.stat().st_size / 1024:.2f} KB')\n",
    "except Exception as e:\n",
    "    print(f'\\n‚ùå Error generating PDF: {e}')\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print('=' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9576f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FINAL SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print('\\n\\n')\n",
    "print('=' * 80)\n",
    "print('HYPERPARAMETER OPTIMIZATION COMPLETE!')\n",
    "print('=' * 80)\n",
    "\n",
    "print(f'\\nüìä Project: {MODEL_NAME} on {YOLO_DATASET_ROOT.name}')\n",
    "print(f'üìÖ Date: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "\n",
    "print(f'\\nüî¨ Optimization Summary:')\n",
    "print(f'  Total Trials: {len(study.trials)}')\n",
    "print(f'  Completed: {len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])}')\n",
    "print(f'  Best Trial: {study.best_trial.number}')\n",
    "print(f'  Best Trial mAP@0.5: {study.best_value:.4f}')\n",
    "print(f'  Duration: {duration}')\n",
    "\n",
    "if 'final_metrics' in globals():\n",
    "    print(f'\\nüéØ Final Model Performance:')\n",
    "    print(f'  mAP@0.5: {final_metrics[\"map50\"]:.4f}')\n",
    "    print(f'  mAP@0.5:0.95: {final_metrics[\"map50_95\"]:.4f}')\n",
    "    print(f'  Precision: {final_metrics[\"precision\"]:.4f}')\n",
    "    print(f'  Recall: {final_metrics[\"recall\"]:.4f}')\n",
    "\n",
    "print(f'\\nüìÅ Generated Files:')\n",
    "print(f'  üìä Optimization Results:')\n",
    "print(f'    - {RUN_DIR / \"best_hyperparameters.json\"}')\n",
    "print(f'    - {RUN_DIR / \"best_hparams.yaml\"}')\n",
    "print(f'    - {RUN_DIR / \"trials_summary.csv\"}')\n",
    "print(f'    - {RUN_DIR / \"optuna_study.pkl\"}')\n",
    "print(f'  üìà Visualizations:')\n",
    "print(f'    - {RUN_DIR / \"optimization_history.html\"}')\n",
    "print(f'    - {RUN_DIR / \"parameter_importance.html\"}')\n",
    "print(f'    - {RUN_DIR / \"parameter_slice.html\"}')\n",
    "print(f'  üìÑ PDF Report:')\n",
    "print(f'    - {RUN_DIR / f\"{MODEL_NAME}_hyperparameter_tuning_report.pdf\"}')\n",
    "\n",
    "if 'final_model_path' in globals():\n",
    "    print(f'  üéØ Final Model:')\n",
    "    print(f'    - {final_model_path}')\n",
    "    print(f'    - {metadata_path}')\n",
    "    print(f'  ‚öôÔ∏è  Training Config:')\n",
    "    print(f'    - {training_config_path}')\n",
    "    print(f'    - {training_config_json}')\n",
    "\n",
    "print(f'\\nüìÇ All results saved to: {RUN_DIR}')\n",
    "\n",
    "print(f'\\nüéì Top 5 Hyperparameters (by importance):')\n",
    "try:\n",
    "    importances = optuna.importance.get_param_importances(study)\n",
    "    for i, (param, importance) in enumerate(list(importances.items())[:5], 1):\n",
    "        print(f'  {i}. {param}: {importance:.4f}')\n",
    "except:\n",
    "    print('  (Not available - requires completed trials with variation)')\n",
    "\n",
    "print(f'\\nüöÄ Next Steps:')\n",
    "print(f'  1. Review PDF report: {RUN_DIR / f\"{MODEL_NAME}_hyperparameter_tuning_report.pdf\"}')\n",
    "print(f'  2. Review optimization visualizations in: {RUN_DIR}')\n",
    "if 'final_model_path' in globals():\n",
    "    print(f'  3. Use final model for inference: {final_model_path}')\n",
    "    print(f'  4. Check training plots in: {training_dir / \"runs\" / f\"{MODEL_NAME}_optimized\"}')\n",
    "else:\n",
    "    print(f'  3. Run final training section to create optimized model')\n",
    "print(f'  5. Consider testing different model sizes (yolov8s, yolov8m, etc.)')\n",
    "print(f'  6. Evaluate on test set for final performance metrics')\n",
    "\n",
    "print('\\n' + '=' * 80)\n",
    "print('SUCCESS! ‚úì')\n",
    "print('=' * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "109394c4",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6f98f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import optuna\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure matplotlib for inline display in notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "\n",
    "print('âœ“ Libraries imported successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2659c792",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d163f0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directories\n",
    "BASE_DIR = Path.cwd().parent\n",
    "\n",
    "# from pathlib import Path\n",
    "# BASE_DIR = Path(\"/computer_vision_yolo\")\n",
    "\n",
    "MODEL_NAME = \"yolov8n\"  # Model name without .pt extension\n",
    "\n",
    "# Choose YOLO model versions that are fully supported with ultralytics:\n",
    "# âœ… YOLOv8: 'yolov8n', 'yolov8s', 'yolov8m', 'yolov8l', 'yolov8x'\n",
    "# âœ… YOLOv9: 'yolov9s', 'yolov9m', 'yolov9l', 'yolov9x'\n",
    "# âœ… YOLOv10: 'yolov10n', 'yolov10s', 'yolov10m', 'yolov10l', 'yolov10x'\n",
    "# âœ… YOLO11: 'yolo11n', 'yolo11s', 'yolo11m', 'yolo11l', 'yolo11x'\n",
    "# âœ… YOLO12: 'yolo12n', 'yolo12s', 'yolo12m', 'yolo12l', 'yolo12x'\n",
    "\n",
    "MODELS_DIR = BASE_DIR / 'models' / MODEL_NAME\n",
    "TMP_DIR = BASE_DIR / 'tmp' / MODEL_NAME\n",
    "RUNS_DIR = BASE_DIR / 'hyperparameter_tuning' / 'runs'\n",
    "\n",
    "# Dataset Selection - Choose one:\n",
    "# Option 1: Full dataset (~100k images) - use for final optimization\n",
    "# YOLO_DATASET_ROOT = BASE_DIR / 'bdd100k_yolo'\n",
    "# DATA_YAML_PATH = YOLO_DATASET_ROOT / 'data.yaml'\n",
    "\n",
    "# Option 2: Limited dataset (representative samples - recommended for quick tuning)\n",
    "YOLO_DATASET_ROOT = BASE_DIR / 'bdd100k_yolo_limited'\n",
    "DATA_YAML_PATH = YOLO_DATASET_ROOT / 'data.yaml'\n",
    "\n",
    "# Verify dataset exists\n",
    "if not DATA_YAML_PATH.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Dataset not found: {DATA_YAML_PATH}\\n\\n\"\n",
    "        f\"Please run the dataset preparation script first:\\n\"\n",
    "        f\"  python3 process_bdd100k_to_yolo_dataset.py\\n\"\n",
    "    )\n",
    "\n",
    "# Tuning configuration\n",
    "N_TRIALS = 20  # Number of optimization trials\n",
    "TIMEOUT_HOURS = 4  # Maximum time for optimization\n",
    "\n",
    "# Generate timestamp and run name\n",
    "RUN_TIMESTAMP = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "RUN_NAME = f'{MODEL_NAME}_tuning_{RUN_TIMESTAMP}'\n",
    "W_B_PROJECT = \"yolo-bdd100k-hyperparameter-tuning\"\n",
    "\n",
    "# Create run-specific directory\n",
    "RUN_DIR = RUNS_DIR / RUN_NAME\n",
    "RUN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create other directories\n",
    "TMP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RUNS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Read number of classes from data.yaml\n",
    "import yaml\n",
    "with open(DATA_YAML_PATH, 'r') as f:\n",
    "    data_config = yaml.safe_load(f)\n",
    "    NUM_CLASSES = data_config['nc']\n",
    "    CLASS_NAMES = {i: name for i, name in enumerate(data_config['names'])}\n",
    "\n",
    "print('âœ“ Configuration loaded')\n",
    "print(f'  Model: {MODEL_NAME}')\n",
    "print(f'  Dataset: {YOLO_DATASET_ROOT.name}')\n",
    "print(f'  Data YAML: {DATA_YAML_PATH}')\n",
    "print(f'  Run directory: {RUN_DIR}')\n",
    "print(f'  Classes: {NUM_CLASSES}')\n",
    "print(f'  Optimization trials: {N_TRIALS}')\n",
    "print(f'  Timeout: {TIMEOUT_HOURS} hours')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af35c3f",
   "metadata": {},
   "source": [
    "## 3. Load Base YOLO Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3deeda88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLO model with automatic download\n",
    "model_path = MODELS_DIR / f'{MODEL_NAME}.pt'\n",
    "\n",
    "if not model_path.exists():\n",
    "    print(f'Model not found at {model_path}')\n",
    "    print(f'Downloading {MODEL_NAME} ...')\n",
    "    \n",
    "    try:\n",
    "        # Download model\n",
    "        MODEL_NAME_n = MODEL_NAME\n",
    "        if MODEL_NAME.startswith('yolo11') or MODEL_NAME.startswith('yolo12'):\n",
    "            MODEL_NAME_n = MODEL_NAME + '.pt'\n",
    "        model = YOLO(MODEL_NAME_n)\n",
    "        \n",
    "        # Create models directory\n",
    "        MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Move from cache\n",
    "        try:\n",
    "            import glob\n",
    "            cache_patterns = [\n",
    "                str(Path.home() / '.cache' / 'ultralytics' / '**' / f'{MODEL_NAME}.pt'),\n",
    "                str(Path.home() / '.config' / 'Ultralytics' / '**' / f'{MODEL_NAME}.pt'),\n",
    "            ]\n",
    "            \n",
    "            model_found = False\n",
    "            for pattern in cache_patterns:\n",
    "                cache_paths = glob.glob(pattern, recursive=True)\n",
    "                if cache_paths:\n",
    "                    shutil.move(cache_paths[0], model_path)\n",
    "                    print(f'âœ“ Model downloaded and saved to {model_path}')\n",
    "                    print(f'  Size: {model_path.stat().st_size / (1024*1024):.1f} MB')\n",
    "                    \n",
    "                    # Clean up cache directory\n",
    "                    cache_dir = Path(cache_paths[0]).parent\n",
    "                    if cache_dir.exists() and not any(cache_dir.iterdir()):\n",
    "                        cache_dir.rmdir()\n",
    "                        print(f'  âœ“ Cleaned up cache directory')\n",
    "                    \n",
    "                    model_found = True\n",
    "                    break\n",
    "            \n",
    "            if not model_found:\n",
    "                print(f'âœ“ Model loaded from ultralytics cache')\n",
    "        except Exception as save_error:\n",
    "            print(f'âš ï¸  Could not move model: {save_error}')\n",
    "            print(f'âœ“ Model loaded successfully from cache')\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f'\\nâŒ Error downloading model: {e}')\n",
    "        raise\n",
    "else:\n",
    "    model = YOLO(str(model_path))\n",
    "    print(f'âœ“ Model loaded from {model_path}')\n",
    "\n",
    "print(f'\\nðŸ“Š Base Model: {MODEL_NAME}')\n",
    "print(f'  Classes in model: {len(model.names)}')\n",
    "print(f'  Task: {model.task}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe0b94d",
   "metadata": {},
   "source": [
    "## 4. Verify Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b15401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify dataset structure is ready\n",
    "print('Verifying YOLO dataset structure...')\n",
    "print(f'\\nðŸ“ Dataset Root: {YOLO_DATASET_ROOT}')\n",
    "\n",
    "# Check splits\n",
    "for split in ['train', 'val', 'test']:\n",
    "    images_dir = YOLO_DATASET_ROOT / 'images' / split\n",
    "    labels_dir = YOLO_DATASET_ROOT / 'labels' / split\n",
    "    \n",
    "    if images_dir.exists() and labels_dir.exists():\n",
    "        num_images = len(list(images_dir.glob('*.jpg'))) + len(list(images_dir.glob('*.png')))\n",
    "        num_labels = len(list(labels_dir.glob('*.txt')))\n",
    "        print(f'  âœ“ {split:5s}: {num_images:6d} images, {num_labels:6d} labels')\n",
    "    else:\n",
    "        print(f'  âš ï¸  {split:5s}: Directory not found')\n",
    "\n",
    "# Verify data.yaml\n",
    "print(f'\\nðŸ“„ Configuration: {DATA_YAML_PATH}')\n",
    "print(f'  Classes: {NUM_CLASSES}')\n",
    "print(f'  Names: {CLASS_NAMES}')\n",
    "\n",
    "print('\\nâœ“ Dataset structure verified and ready for training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf76930",
   "metadata": {},
   "source": [
    "## 5. Define Hyperparameter Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d1ae35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_hyperparameters(trial):\n",
    "    \"\"\"\n",
    "    Define the hyperparameter search space for YOLO optimization.\n",
    "    Conservative ranges around YOLO defaults to ensure training stability.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Hyperparameters to test\n",
    "    \"\"\"\n",
    "    \n",
    "    # Training hyperparameters with conservative ranges\n",
    "    hyperparams = {\n",
    "        # Optimizer settings - narrower ranges around proven defaults\n",
    "        'lr0': trial.suggest_float('lr0', 0.0005, 0.01, log=True),  # Initial learning rate (default ~0.01)\n",
    "        'lrf': trial.suggest_float('lrf', 0.01, 0.2),  # Final learning rate factor (default 0.01)\n",
    "        'momentum': trial.suggest_float('momentum', 0.85, 0.98),  # SGD momentum (default 0.937)\n",
    "        'weight_decay': trial.suggest_float('weight_decay', 0.0001, 0.001, log=True),  # (default 0.0005)\n",
    "        \n",
    "        # Data augmentation - moderate values\n",
    "        # 'hsv_h': trial.suggest_float('hsv_h', 0.0, 0.02),  # HSV Hue (default 0.015)\n",
    "        # 'hsv_s': trial.suggest_float('hsv_s', 0.3, 0.9),  # HSV Saturation (default 0.7)\n",
    "        # 'hsv_v': trial.suggest_float('hsv_v', 0.2, 0.6),  # HSV Value (default 0.4)\n",
    "        # 'degrees': trial.suggest_float('degrees', 0.0, 10.0),  # Rotation (default 0.0)\n",
    "        # 'translate': trial.suggest_float('translate', 0.05, 0.2),  # Translation (default 0.1)\n",
    "        # 'scale': trial.suggest_float('scale', 0.0, 0.5),  # Scaling (default 0.5)\n",
    "        # 'flipud': trial.suggest_float('flipud', 0.0, 0.1),  # Flip up-down (default 0.0)\n",
    "        # 'fliplr': trial.suggest_float('fliplr', 0.3, 0.7),  # Flip left-right (default 0.5)\n",
    "        # 'mosaic': trial.suggest_float('mosaic', 0.5, 1.0),  # Mosaic augmentation (default 1.0)\n",
    "        # 'mixup': trial.suggest_float('mixup', 0.0, 0.1),  # Mixup augmentation (default 0.0)\n",
    "        \n",
    "        # Loss function weights - stay close to defaults\n",
    "        'box': trial.suggest_float('box', 6.0, 8.5),  # Box loss weight (default 7.5)\n",
    "        'cls': trial.suggest_float('cls', 0.4, 0.7),  # Classification loss weight (default 0.5)\n",
    "        'dfl': trial.suggest_float('dfl', 1.3, 1.7),  # DFL loss weight (default 1.5)\n",
    "        \n",
    "        # Training settings\n",
    "        'warmup_epochs': trial.suggest_int('warmup_epochs', 2, 5),  # (default 3)\n",
    "        'warmup_momentum': trial.suggest_float('warmup_momentum', 0.7, 0.95),  # (default 0.8)\n",
    "        'warmup_bias_lr': trial.suggest_float('warmup_bias_lr', 0.05, 0.15),  # (default 0.1)\n",
    "        \n",
    "        # Fixed parameters - increased for better learning\n",
    "        'epochs': 50,  # Increased for better convergence\n",
    "        'batch': 16,\n",
    "        'imgsz': 640,\n",
    "        'patience': 15,  # More patience for convergence\n",
    "        'save': False,  # Don't save intermediate models\n",
    "        'plots': False,  # Don't generate plots for each trial\n",
    "        'cache': True,  # Cache images for faster training\n",
    "        'workers': 8,  # Use multiple workers\n",
    "        'close_mosaic': 10,  # Disable mosaic in last 10 epochs for better convergence\n",
    "    }\n",
    "    \n",
    "    return hyperparams\n",
    "\n",
    "print('âœ“ Hyperparameter search space defined')\n",
    "print('  Strategy: Conservative ranges around YOLO defaults')\n",
    "print('  Parameters to optimize:')\n",
    "print('    - Learning rate (lr0, lrf) - narrow range')\n",
    "print('    - Optimizer (momentum, weight_decay) - near defaults')\n",
    "print('    - Data augmentation (hsv, geometric, mosaic, mixup) - moderate')\n",
    "print('    - Loss weights (box, cls, dfl) - close to defaults')\n",
    "print('    - Warmup settings')\n",
    "print('  Fixed settings:')\n",
    "print('    - Epochs: 50 (increased for better convergence)')\n",
    "print('    - Batch: 16')\n",
    "print('    - Image size: 640')\n",
    "print('    - Patience: 15')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8326b5",
   "metadata": {},
   "source": [
    "## 6. Define Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5575796",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Objective function for Optuna optimization.\n",
    "    Trains a YOLO model with trial hyperparameters and returns validation mAP@0.5.\n",
    "    \n",
    "    Args:\n",
    "        trial: Optuna trial object\n",
    "        \n",
    "    Returns:\n",
    "        float: Validation mAP@0.5 (metric to maximize)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get hyperparameters for this trial\n",
    "    hyperparams = define_hyperparameters(trial)\n",
    "    \n",
    "    # Create trial-specific directory\n",
    "    trial_dir = RUN_DIR / f'trial_{trial.number:03d}'\n",
    "    trial_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        # Initialize W&B for this trial\n",
    "        try:\n",
    "            import wandb\n",
    "            wandb.init(\n",
    "                project=W_B_PROJECT,\n",
    "                name=f'{MODEL_NAME}_trial_{trial.number:03d}',\n",
    "                config=hyperparams,\n",
    "                reinit=True\n",
    "            )\n",
    "        except:\n",
    "            wandb = None\n",
    "        \n",
    "        # Load fresh model for this trial\n",
    "        model = YOLO(str(model_path))\n",
    "        \n",
    "        # Print trial info\n",
    "        print(f'\\n[Trial {trial.number}] Training with:')\n",
    "        print(f'  lr0={hyperparams[\"lr0\"]:.6f}, lrf={hyperparams[\"lrf\"]:.4f}')\n",
    "        print(f'  momentum={hyperparams[\"momentum\"]:.4f}, weight_decay={hyperparams[\"weight_decay\"]:.6f}')\n",
    "        print(f'  box={hyperparams[\"box\"]:.2f}, cls={hyperparams[\"cls\"]:.2f}, dfl={hyperparams[\"dfl\"]:.2f}')\n",
    "        \n",
    "        # Train with hyperparameters using data.yaml directly\n",
    "        results = model.train(\n",
    "            data=str(DATA_YAML_PATH),\n",
    "            project=str(trial_dir),\n",
    "            name='train',\n",
    "            exist_ok=True,\n",
    "            verbose=False,\n",
    "            **hyperparams\n",
    "        )\n",
    "        \n",
    "        # Get validation metrics\n",
    "        val_results = model.val(\n",
    "            data=str(data_yaml_path),\n",
    "            split=USED_DATA_SPLIT,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        # Extract mAP@0.5 as optimization metric\n",
    "        map50 = float(val_results.box.map50)\n",
    "        map50_95 = float(val_results.box.map)\n",
    "        precision = float(val_results.box.mp)\n",
    "        recall = float(val_results.box.mr)\n",
    "        \n",
    "        # Log to W&B\n",
    "        if wandb:\n",
    "            wandb.log({\n",
    "                'val/mAP@0.5': map50,\n",
    "                'val/mAP@0.5:0.95': map50_95,\n",
    "                'val/precision': precision,\n",
    "                'val/recall': recall\n",
    "            })\n",
    "            wandb.finish()\n",
    "        \n",
    "        # Save trial results\n",
    "        trial_results = {\n",
    "            'trial_number': trial.number,\n",
    "            'hyperparameters': hyperparams,\n",
    "            'metrics': {\n",
    "                'map50': map50,\n",
    "                'map50_95': map50_95,\n",
    "                'precision': precision,\n",
    "                'recall': recall\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        with open(trial_dir / 'results.json', 'w') as f:\n",
    "            json.dump(trial_results, f, indent=2)\n",
    "        \n",
    "        print(f'Trial {trial.number}: mAP@0.5={map50:.4f}, mAP@0.5:0.95={map50_95:.4f}')\n",
    "        \n",
    "        return map50\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'  âŒ Trial {trial.number} failed with error: {e}')\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        if wandb:\n",
    "            wandb.finish()\n",
    "        return 0.0  # Return poor score for failed trials\n",
    "\n",
    "print('âœ“ Objective function defined')\n",
    "print('  Optimization metric: mAP@0.5 (to maximize)')\n",
    "print('  Additional tracking: mAP@0.5:0.95, precision, recall')\n",
    "print('  Validation: Uses training results + explicit validation if needed')\n",
    "print('  Error handling: Detailed logging and fallback to small non-zero scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b2c034",
   "metadata": {},
   "source": [
    "## 7. Run Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e116f130",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 80)\n",
    "print('STARTING HYPERPARAMETER OPTIMIZATION')\n",
    "print('=' * 80)\n",
    "print(f'Model: {MODEL_NAME}')\n",
    "print(f'Dataset: {USED_DATASET} - {USED_DATA_SPLIT} split')\n",
    "print(f'Number of trials: {N_TRIALS}')\n",
    "print(f'Timeout: {TIMEOUT_HOURS} hours')\n",
    "print(f'Strategy: Conservative ranges + longer training (50 epochs)')\n",
    "print('=' * 80)\n",
    "\n",
    "# Create Optuna study with more lenient pruning\n",
    "study = optuna.create_study(\n",
    "    study_name=f'{MODEL_NAME}_tuning',\n",
    "    direction='maximize',  # Maximize mAP@0.5\n",
    "    sampler=optuna.samplers.TPESampler(seed=42, n_startup_trials=5),  # More random exploration\n",
    "    pruner=optuna.pruners.MedianPruner(\n",
    "        n_startup_trials=8,  # Don't prune first 8 trials\n",
    "        n_warmup_steps=20,  # Wait 20 steps before pruning\n",
    "        interval_steps=5  # Check every 5 steps\n",
    "    )\n",
    ")\n",
    "\n",
    "# Run optimization\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=N_TRIALS,\n",
    "    timeout=TIMEOUT_HOURS * 3600,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "print('\\n' + '=' * 80)\n",
    "print('OPTIMIZATION COMPLETED')\n",
    "print('=' * 80)\n",
    "print(f'Total trials: {len(study.trials)}')\n",
    "print(f'Best trial: {study.best_trial.number}')\n",
    "print(f'Best mAP@0.5: {study.best_value:.4f}')\n",
    "print('=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ff99f5",
   "metadata": {},
   "source": [
    "## 8. Analyze Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3823505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best hyperparameters\n",
    "best_params = study.best_params\n",
    "\n",
    "print('=' * 80)\n",
    "print('BEST HYPERPARAMETERS')\n",
    "print('=' * 80)\n",
    "print(json.dumps(best_params, indent=2))\n",
    "print('=' * 80)\n",
    "\n",
    "# Save best parameters\n",
    "best_params_path = RUN_DIR / 'best_hyperparameters.json'\n",
    "with open(best_params_path, 'w') as f:\n",
    "    json.dump({\n",
    "        'best_trial': study.best_trial.number,\n",
    "        'best_value': study.best_value,\n",
    "        'hyperparameters': best_params,\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(f'\\nâœ“ Best hyperparameters saved to: {best_params_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24aed975",
   "metadata": {},
   "source": [
    "## 9. Visualize Optimization Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d33d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot optimization history\n",
    "fig1 = plot_optimization_history(study)\n",
    "fig1.update_layout(title=f'{MODEL_NAME} Hyperparameter Optimization History')\n",
    "fig1.show()\n",
    "\n",
    "# Save figure\n",
    "optimization_history_path = RUN_DIR / 'optimization_history.png'\n",
    "fig1.write_image(str(optimization_history_path))\n",
    "print(f'âœ“ Optimization history saved to: {optimization_history_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cc1e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot parameter importances\n",
    "try:\n",
    "    fig2 = plot_param_importances(study)\n",
    "    fig2.update_layout(title=f'{MODEL_NAME} Hyperparameter Importance')\n",
    "    fig2.show()\n",
    "    \n",
    "    # Save figure\n",
    "    param_importance_path = RUN_DIR / 'parameter_importance.png'\n",
    "    fig2.write_image(str(param_importance_path))\n",
    "    print(f'âœ“ Parameter importance saved to: {param_importance_path}')\n",
    "except (RuntimeError, ValueError) as e:\n",
    "    print(f'âš ï¸  Could not generate parameter importance plot: {e}')\n",
    "    print('  This can happen when trials have insufficient data variation.')\n",
    "    param_importance_path = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1900ad83",
   "metadata": {},
   "source": [
    "## 10. Create Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c210c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive results summary\n",
    "trials_data = []\n",
    "for trial in study.trials:\n",
    "    trials_data.append({\n",
    "        'trial': trial.number,\n",
    "        'mAP@0.5': trial.value,\n",
    "        'state': trial.state.name,\n",
    "        **trial.params\n",
    "    })\n",
    "\n",
    "df_trials = pd.DataFrame(trials_data)\n",
    "df_trials = df_trials.sort_values('mAP@0.5', ascending=False)\n",
    "\n",
    "print('=' * 80)\n",
    "print('TOP 10 TRIALS')\n",
    "print('=' * 80)\n",
    "print(df_trials.head(10).to_string(index=False))\n",
    "print('=' * 80)\n",
    "\n",
    "# Save trials summary\n",
    "trials_csv_path = RUN_DIR / 'trials_summary.csv'\n",
    "df_trials.to_csv(trials_csv_path, index=False)\n",
    "print(f'\\nâœ“ Trials summary saved to: {trials_csv_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923833ab",
   "metadata": {},
   "source": [
    "## 11. Save Hyperparameters for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d702ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 80)\n",
    "print('SAVING BEST HYPERPARAMETERS FOR TRAINING')\n",
    "print('=' * 80)\n",
    "\n",
    "# Create training directory\n",
    "training_dir = BASE_DIR / 'training'\n",
    "training_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Prepare training hyperparameters with recommended settings\n",
    "training_params = best_params.copy()\n",
    "training_params.update({\n",
    "    'epochs': 100,  # Full training epochs\n",
    "    'batch': 16,\n",
    "    'imgsz': 640,\n",
    "    'patience': 20,\n",
    "    'save': True,\n",
    "    'plots': True,\n",
    "    'verbose': True,\n",
    "    'cache': True,\n",
    "    'workers': 8,\n",
    "    'project': 'training',  # Project directory\n",
    "    'name': MODEL_NAME,  # Experiment name\n",
    "    'exist_ok': True\n",
    "})\n",
    "\n",
    "# Save hyperparameters for training\n",
    "training_params_path = training_dir / f'{MODEL_NAME}_best_hyperparameters.json'\n",
    "with open(training_params_path, 'w') as f:\n",
    "    json.dump({\n",
    "        'model': MODEL_NAME,\n",
    "        'base_model_path': str(model_path),\n",
    "        'dataset_root': str(YOLO_DATASET_ROOT),\n",
    "        'data_yaml_path': str(DATA_YAML_PATH),\n",
    "        'optimization_results': {\n",
    "            'best_trial': study.best_trial.number,\n",
    "            'best_map50': study.best_value,\n",
    "            'total_trials': len(study.trials)\n",
    "        },\n",
    "        'hyperparameters': training_params,\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'notes': 'Use these hyperparameters for full model training'\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(f'âœ“ Training hyperparameters saved to: {training_params_path}')\n",
    "print(f'\\nRecommended training command:')\n",
    "print(f'  model = YOLO(\"{model_path}\")')\n",
    "print(f'  model.train(data=\"{DATA_YAML_PATH}\", **hyperparameters)')\n",
    "print('\\nHyperparameters optimized for:')\n",
    "for key, value in best_params.items():\n",
    "    print(f'  {key}: {value}')\n",
    "print('=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585a97a5",
   "metadata": {},
   "source": [
    "## 12. Generate PDF Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3c3580",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.lib import colors as rl_colors\n",
    "from reportlab.lib.units import inch\n",
    "from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer, Image, PageBreak\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.enums import TA_CENTER, TA_LEFT\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "print('=' * 80)\n",
    "print('GENERATING PDF REPORT')\n",
    "print('=' * 80)\n",
    "\n",
    "# Create PDF report\n",
    "pdf_report_path = RUN_DIR / f'{MODEL_NAME}_hyperparameter_tuning_report.pdf'\n",
    "\n",
    "doc = SimpleDocTemplate(str(pdf_report_path), pagesize=A4,\n",
    "                       rightMargin=30, leftMargin=30,\n",
    "                       topMargin=30, bottomMargin=30)\n",
    "\n",
    "story = []\n",
    "styles = getSampleStyleSheet()\n",
    "\n",
    "# Custom styles\n",
    "title_style = ParagraphStyle(\n",
    "    'CustomTitle',\n",
    "    parent=styles['Heading1'],\n",
    "    fontSize=24,\n",
    "    textColor=rl_colors.HexColor('#2c3e50'),\n",
    "    spaceAfter=30,\n",
    "    alignment=TA_CENTER\n",
    ")\n",
    "\n",
    "heading_style = ParagraphStyle(\n",
    "    'CustomHeading',\n",
    "    parent=styles['Heading2'],\n",
    "    fontSize=16,\n",
    "    textColor=rl_colors.HexColor('#34495e'),\n",
    "    spaceAfter=12,\n",
    "    spaceBefore=20\n",
    ")\n",
    "\n",
    "# Title\n",
    "story.append(Paragraph(f'{MODEL_NAME} Hyperparameter Tuning Report', title_style))\n",
    "story.append(Spacer(1, 12))\n",
    "\n",
    "# Configuration info\n",
    "info_data = [\n",
    "    ['Model:', MODEL_NAME],\n",
    "    ['Dataset:', f'{USED_DATASET} - {USED_DATA_SPLIT} split'],\n",
    "    ['Timestamp:', datetime.now().strftime('%Y-%m-%d %H:%M:%S')],\n",
    "    ['Total Trials:', str(len(study.trials))],\n",
    "    ['Best Trial:', str(study.best_trial.number)],\n",
    "    ['Best mAP@0.5:', f'{study.best_value:.4f}']\n",
    "]\n",
    "\n",
    "info_table = Table(info_data, colWidths=[2.2*inch, 3.8*inch])\n",
    "info_table.setStyle(TableStyle([\n",
    "    ('BACKGROUND', (0, 0), (-1, -1), rl_colors.HexColor('#ecf0f1')),\n",
    "    ('TEXTCOLOR', (0, 0), (-1, -1), rl_colors.black),\n",
    "    ('ALIGN', (0, 0), (-1, -1), 'LEFT'),\n",
    "    ('FONTNAME', (0, 0), (0, -1), 'Helvetica-Bold'),\n",
    "    ('FONTSIZE', (0, 0), (-1, -1), 10),\n",
    "    ('BOTTOMPADDING', (0, 0), (-1, -1), 8),\n",
    "    ('TOPPADDING', (0, 0), (-1, -1), 8),\n",
    "    ('GRID', (0, 0), (-1, -1), 1, rl_colors.white)\n",
    "]))\n",
    "story.append(info_table)\n",
    "story.append(Spacer(1, 20))\n",
    "\n",
    "# Best hyperparameters\n",
    "story.append(PageBreak())\n",
    "story.append(Paragraph('Best Hyperparameters', heading_style))\n",
    "\n",
    "hyperparam_data = [['Parameter', 'Value']]\n",
    "for key, value in best_params.items():\n",
    "    hyperparam_data.append([key, f'{value:.6f}' if isinstance(value, float) else str(value)])\n",
    "\n",
    "hyperparam_table = Table(hyperparam_data, colWidths=[3*inch, 3*inch])\n",
    "hyperparam_table.setStyle(TableStyle([\n",
    "    ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#3498db')),\n",
    "    ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n",
    "    ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "    ('FONTSIZE', (0, 0), (-1, 0), 12),\n",
    "    ('FONTSIZE', (0, 1), (-1, -1), 9),\n",
    "    ('BOTTOMPADDING', (0, 0), (-1, -1), 6),\n",
    "    ('TOPPADDING', (0, 0), (-1, -1), 6),\n",
    "    ('ROWBACKGROUNDS', (0, 1), (-1, -1), [rl_colors.white, rl_colors.lightgrey]),\n",
    "    ('GRID', (0, 0), (-1, -1), 1, rl_colors.black)\n",
    "]))\n",
    "story.append(hyperparam_table)\n",
    "story.append(Spacer(1, 20))\n",
    "\n",
    "# Top 10 trials\n",
    "story.append(PageBreak())\n",
    "story.append(Paragraph('Top 10 Trials', heading_style))\n",
    "\n",
    "top10_data = [['Trial', 'mAP@0.5', 'State']]\n",
    "for _, row in df_trials.head(10).iterrows():\n",
    "    top10_data.append([\n",
    "        str(int(row['trial'])),\n",
    "        f\"{row['mAP@0.5']:.4f}\",\n",
    "        row['state']\n",
    "    ])\n",
    "\n",
    "top10_table = Table(top10_data, colWidths=[1.5*inch, 2*inch, 2.5*inch])\n",
    "top10_table.setStyle(TableStyle([\n",
    "    ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#27ae60')),\n",
    "    ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),\n",
    "    ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "    ('FONTSIZE', (0, 0), (-1, 0), 11),\n",
    "    ('FONTSIZE', (0, 1), (-1, -1), 9),\n",
    "    ('BOTTOMPADDING', (0, 0), (-1, -1), 6),\n",
    "    ('TOPPADDING', (0, 0), (-1, -1), 6),\n",
    "    ('ROWBACKGROUNDS', (0, 1), (-1, -1), [rl_colors.white, rl_colors.lightgrey]),\n",
    "    ('GRID', (0, 0), (-1, -1), 1, rl_colors.black)\n",
    "]))\n",
    "story.append(top10_table)\n",
    "story.append(Spacer(1, 20))\n",
    "\n",
    "# Optimization history\n",
    "story.append(PageBreak())\n",
    "story.append(Paragraph('Optimization History', heading_style))\n",
    "story.append(Spacer(1, 12))\n",
    "\n",
    "if optimization_history_path.exists():\n",
    "    try:\n",
    "        with PILImage.open(optimization_history_path) as img:\n",
    "            img_width, img_height = img.size\n",
    "            aspect_ratio = img_height / img_width\n",
    "            pdf_width = 6.5 * inch\n",
    "            pdf_height = pdf_width * aspect_ratio\n",
    "            if pdf_height > 7 * inch:\n",
    "                pdf_height = 7 * inch\n",
    "                pdf_width = pdf_height / aspect_ratio\n",
    "            story.append(Image(str(optimization_history_path), width=pdf_width, height=pdf_height))\n",
    "    except Exception as e:\n",
    "        print(f'Warning: Could not load optimization history: {e}')\n",
    "        story.append(Paragraph('Optimization history chart not available.', styles['Normal']))\n",
    "else:\n",
    "    story.append(Paragraph('Optimization history chart not found.', styles['Normal']))\n",
    "\n",
    "story.append(Spacer(1, 20))\n",
    "\n",
    "# Parameter importance\n",
    "story.append(PageBreak())\n",
    "story.append(Paragraph('Parameter Importance', heading_style))\n",
    "story.append(Spacer(1, 12))\n",
    "\n",
    "if param_importance_path and param_importance_path.exists():\n",
    "    try:\n",
    "        with PILImage.open(param_importance_path) as img:\n",
    "            img_width, img_height = img.size\n",
    "            aspect_ratio = img_height / img_width\n",
    "            pdf_width = 6.5 * inch\n",
    "            pdf_height = pdf_width * aspect_ratio\n",
    "            if pdf_height > 7 * inch:\n",
    "                pdf_height = 7 * inch\n",
    "                pdf_width = pdf_height / aspect_ratio\n",
    "            story.append(Image(str(param_importance_path), width=pdf_width, height=pdf_height))\n",
    "    except Exception as e:\n",
    "        print(f'Warning: Could not load parameter importance: {e}')\n",
    "        story.append(Paragraph('Parameter importance chart not available.', styles['Normal']))\n",
    "else:\n",
    "    story.append(Paragraph('Parameter importance chart not available or could not be generated.', styles['Normal']))\n",
    "\n",
    "story.append(Spacer(1, 20))\n",
    "\n",
    "# Footer\n",
    "story.append(Spacer(1, 30))\n",
    "story.append(Paragraph('Generated by YOLO Hyperparameter Tuning Notebook',\n",
    "                      ParagraphStyle('Footer', parent=styles['Normal'],\n",
    "                                   alignment=TA_CENTER, textColor=rl_colors.grey)))\n",
    "story.append(Paragraph('BDD100K Dataset - Computer Vision Project',\n",
    "                      ParagraphStyle('Footer2', parent=styles['Normal'],\n",
    "                                   alignment=TA_CENTER, textColor=rl_colors.grey)))\n",
    "\n",
    "# Build PDF\n",
    "doc.build(story)\n",
    "\n",
    "print(f'âœ“ PDF report generated: {pdf_report_path}')\n",
    "print(f'  Size: {pdf_report_path.stat().st_size / 1024:.2f} KB')\n",
    "print('=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b5fda5",
   "metadata": {},
   "source": [
    "## 13. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9576f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 80)\n",
    "print('HYPERPARAMETER TUNING COMPLETED')\n",
    "print('=' * 80)\n",
    "print(f'\\nModel: {MODEL_NAME}')\n",
    "print(f'Dataset: {USED_DATASET} - {USED_DATA_SPLIT} split')\n",
    "print(f'\\nOptimization Results:')\n",
    "print(f'  Total trials: {len(study.trials)}')\n",
    "print(f'  Best trial: {study.best_trial.number}')\n",
    "print(f'  Best mAP@0.5: {study.best_value:.4f}')\n",
    "print(f'\\nOutput Directory: {RUN_DIR}')\n",
    "print(f'\\nGenerated Files:')\n",
    "print(f'  ðŸ“„ Best hyperparameters: best_hyperparameters.json')\n",
    "print(f'  ðŸ“Š Trials summary: trials_summary.csv')\n",
    "print(f'  ðŸ“ˆ Optimization history: optimization_history.png')\n",
    "print(f'  ðŸ“Š Parameter importance: parameter_importance.png')\n",
    "print(f'  ðŸ“„ PDF Report: {MODEL_NAME}_hyperparameter_tuning_report.pdf')\n",
    "print(f'  ðŸŽ¯ Training config: ../training/{MODEL_NAME}_best_hyperparameters.json')\n",
    "print(f'\\nðŸ’¾ All results saved to: {RUN_DIR}')\n",
    "print(f'ðŸ“Š W&B Project: {W_B_PROJECT}')\n",
    "print(f'\\nðŸš€ Next Steps:')\n",
    "print(f'  1. Review the PDF report')\n",
    "print(f'  2. Use hyperparameters from training/{MODEL_NAME}_best_hyperparameters.json')\n",
    "print(f'  3. Train your model with the optimized hyperparameters')\n",
    "print('=' * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
